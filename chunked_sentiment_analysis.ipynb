{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/homebrew/Cellar/apache-spark/3.5.1/libexec/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/kravisankaran/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/kravisankaran/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7d34931d-53c6-42fd-8983-9a4c57ddde0b;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.3.3 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.500 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.500 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.17.0 in central\n",
      ":: resolution report :: resolve 2207ms :: artifacts dl 42ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.500 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.3.3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.17.0 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   83  |   0   |   0   |   5   ||   78  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7d34931d-53c6-42fd-8983-9a4c57ddde0b\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 78 already retrieved (0kB/41ms)\n",
      "24/04/25 15:07:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "allocated_memory = 18 * 0.75 \n",
    "\n",
    "# create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"ReadJSON\")\\\n",
    ".config(\"spark.executor.memory\", \"6g\") \\\n",
    ".master(\"local[*]\")  \\\n",
    ".config(\"spark.driver.memory\", \"4g\") \\\n",
    ".config(\"spark.network.timeout\", \"800s\")\\\n",
    ".config(\"spark.executor.heartbeatInterval\", \"200s\")\\\n",
    ".config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\")\\\n",
    ".config(\"spark.driver.extraJavaOptions\", \"-XX:+UseG1GC\")\\\n",
    ".config(\"spark.memory.fraction\", \"0.8\") \\\n",
    ".config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.3.3\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, BooleanType, IntegerType, ArrayType\n",
    "# targetUDF = F.udf(lambda x: 1 if x >= 4.0 else (0 if x == 3.0 else -1), IntegerType())\n",
    "targetUDF = F.udf(lambda x: 1 if x >= 4.0 else 0, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_objects = []\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, BooleanType, IntegerType\n",
    "#\"reviewerID\": \"A8WEXFRWX1ZHH\", \n",
    "# \"asin\": \"0209688726\", \n",
    "# \"style\": {\"Color:\": \" AC\"}, \n",
    "# \"reviewerName\": \"Goldengate\",\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"overall\", FloatType(), True),\n",
    "    StructField(\"verified\", BooleanType(), True),\n",
    "    StructField(\"reviewTime\", StringType(), True),\n",
    "    StructField(\"reviewerID\", StringType(), True),\n",
    "    StructField(\"asin\", StringType(), True),\n",
    "    StructField(\"style\", StructType([StructField(\"Color:\", StringType(), True)]), True),\n",
    "    StructField(\"reviewerName\", StringType(), True),\n",
    "    StructField(\"reviewText\", StringType(), True),\n",
    "    StructField(\"unixReviewTime\", IntegerType(), True)\n",
    "    \n",
    "])\n",
    "def pre_process(chunk):\n",
    "    print(\"Processing chunk\")\n",
    "    df = spark.createDataFrame(json_objects, schema=schema)\n",
    "    reduced_df = df.select(\"overall\", \"reviewerID\", \"asin\", \"reviewText\")\n",
    "    unique_df = reduced_df.dropDuplicates([\"reviewerID\", \"asin\"])\n",
    "    unique_df = unique_df.filter(unique_df.reviewText.isNotNull())\n",
    "    df_sentiment = unique_df.withColumn(\"sentiment\", targetUDF(unique_df[\"overall\"]))\n",
    "    return df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import json\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# from pyspark.sql.functions import rand\n",
    "# from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "# # Define the maximum file size in bytes (10MB)\n",
    "# max_file_size = 10 * 1024 * 1024\n",
    "\n",
    "# json_objects = []\n",
    "\n",
    "# # Read the file line by line until the maximum file size is reached\n",
    "# with open(json_training_file_path, 'r') as file:\n",
    "#     total_size = 0\n",
    "#     for line in file:\n",
    "#         # Calculate the size of the current line\n",
    "#         line_size = sys.getsizeof(line)\n",
    "\n",
    "#         # If adding the current line exceeds the maximum file size, stop reading\n",
    "#         if total_size + line_size > max_file_size:\n",
    "#             print(line_size, total_size)\n",
    "#             # Create a DataFrame from the list of JSON objects\n",
    "#             df = spark.createDataFrame(json_objects)\n",
    "#             reduced_df = df.select(\"overall\", \"reviewerID\", \"asin\", \"reviewText\")\n",
    "#             unique_df = reduced_df.dropDuplicates([\"reviewerID\", \"asin\"])\n",
    "#             df_sentiment = unique_df.withColumn(\"sentiment\", targetUDF(unique_df[\"overall\"]))\n",
    "#             tokenizer = Tokenizer(inputCol  = \"reviewText\",\n",
    "#                       outputCol = \"token\")\n",
    "#             # Remove the rows with missing values and tokenize\n",
    "#             df_train_tokenized = tokenizer.transform(df_sentiment.filter(unique_df.reviewText.isNotNull()))\n",
    "#             # remove hashtags, call outs and web addresses\n",
    "#             df4_train = df_train_tokenized.withColumn(\"tokens_re\", removeWEBUDF(df_train_tokenized[\"token\"]))\n",
    "#             # remove non english characters\n",
    "#             df4_train = df4_train.withColumn(\"tokens_clean\", normalizeUDF(df4_train[\"tokens_re\"]))\n",
    "#             # rename columns\n",
    "#             df5_train = df4_train.drop(\"token\",\"tokens_re\")\n",
    "#             df5_train = df5_train.withColumnRenamed(\"tokens_clean\", \"tokens\")\n",
    "#             # remove reviews where the tokens array is empty, i.e. where it was just\n",
    "#             # a hashtag, callout, numbers, web adress etc.\n",
    "#             df6_train = df5_train.where(F.size(F.col(\"tokens\")) > 0)\n",
    "#             df_train_for_model = df6_train.select(\"reviewText\",\"sentiment\").withColumnRenamed(\"sentiment\", \"label\")\n",
    "#             shuffled_train_df = df_train_for_model.orderBy(rand())\n",
    "#             if os.path.exists('bigram_pipeline_model'):\n",
    "#                 loaded_model = PipelineModel.load('bigram_pipeline_model')\n",
    "#                 stages_steps = loaded_model.stages\n",
    "#                 updated_model = Pipeline(stages = stages_steps).fit(shuffled_train_df)\n",
    "#                 shutil.rmtree('bigram_pipeline_model')\n",
    "#             else:\n",
    "#                 updated_model = bigram_pipeline.fit(shuffled_train_df)\n",
    "\n",
    "#             PipelineModel.save(updated_model, 'bigram_pipeline_model')\n",
    "#             print('Model saved')\n",
    "#             json_objects = []\n",
    "#             total_size = 0\n",
    "#         # Otherwise, add the line to the list of JSON objects\n",
    "#         json_objects.append(json.loads(line))\n",
    "#         total_size += line_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from pyspark import keyword_only\n",
    "import numpy as np\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param\n",
    "\n",
    "\n",
    "class PorterStemming(Transformer, HasInputCol, HasOutputCol):\n",
    "    \"\"\"\n",
    "    PosterStemming class using the NLTK Porter Stemmer\n",
    "    \n",
    "    This comes from https://stackoverflow.com/questions/32331848/create-a-custom-transformer-in-pyspark-ml\n",
    "    Adapted to work with the Porter Stemmer from NLTK.\n",
    "    \"\"\"\n",
    "    \n",
    "    @keyword_only\n",
    "    def __init__(self, \n",
    "                 inputCol  : str = None, \n",
    "                 outputCol : str = None, \n",
    "                 min_size  : int = None):\n",
    "        \"\"\"\n",
    "        Constructor takes in the input column name, output column name,\n",
    "        plus the minimum legnth of a token (min_size)\n",
    "        \"\"\"\n",
    "        # call Transformer classes constructor since were extending it.\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # set Parameter objects minimum token size\n",
    "        self.min_size = Param(self, \"min_size\", \"\")\n",
    "        self._setDefault(min_size=0)\n",
    "\n",
    "        # set the input keywork arguments\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "        # initialize Stemmer object\n",
    "        self.stemmer  = PorterStemmer()\n",
    "\n",
    "        \n",
    "    @keyword_only\n",
    "    def setParams(self, \n",
    "                  inputCol  : str = None, \n",
    "                  outputCol : str = None, \n",
    "                  min_size  : int = None\n",
    "      ) -> None:\n",
    "        \"\"\"\n",
    "        Function to set the keyword arguemnts\n",
    "        \"\"\"\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    \n",
    "\n",
    "    def _stem_func(self, words  : list) -> list:\n",
    "        \"\"\"\n",
    "        Stemmer function call that performs stemming on a\n",
    "        list of tokens in words and returns a list of tokens\n",
    "        that have meet the minimum length requiremnt.\n",
    "        \"\"\"\n",
    "        # We need a way to get min_size and cannot access it \n",
    "        # with self.min_size\n",
    "        min_size       = self.getMinSize()\n",
    "\n",
    "        # stem that actual tokens by applying \n",
    "        # self.stemmer.stem function to each token in \n",
    "        # the words list\n",
    "        stemmed_words  = map(self.stemmer.stem, words)\n",
    "\n",
    "        # now create the new list of tokens from\n",
    "        # stemmed_words by filtering out those\n",
    "        # that are not of legnth > min_size\n",
    "        filtered_words = filter(lambda x: len(x) > min_size, stemmed_words)\n",
    "\n",
    "        return list(filtered_words)\n",
    "    \n",
    "    def _transform(self, df: DataFrame) -> DataFrame:\n",
    "        \"\"\"\n",
    "        Transform function is the method that is called in the \n",
    "        MLPipleline.  We have to override this function for our own use\n",
    "        and have it call the _stem_func.\n",
    "\n",
    "        Notice how it takes in a type DataFrame and returns type Dataframe\n",
    "        \"\"\"\n",
    "        # Get the names of the input and output columns to use\n",
    "        out_col       = self.getOutputCol()\n",
    "        in_col        = self.getInputCol()\n",
    "\n",
    "        # create the stemming function UDF by wrapping the stemmer \n",
    "        # method function\n",
    "        stem_func_udf = F.udf(self._stem_func, ArrayType(StringType()))\n",
    "        \n",
    "        # now apply that UDF to the column in the dataframe to return\n",
    "        # a new column that has the same list of words after being stemmed\n",
    "        df2           = df.withColumn(out_col, stem_func_udf(df[in_col]))\n",
    "\n",
    "        return df2\n",
    "  \n",
    "  \n",
    "    def setMinSize(self,value):\n",
    "        \"\"\"\n",
    "        This method sets the minimum size value\n",
    "        for the _paramMap dictionary.\n",
    "        \"\"\"\n",
    "        self._paramMap[self.min_size] = value\n",
    "        return self\n",
    "\n",
    "    def getMinSize(self) -> int:\n",
    "        \"\"\"\n",
    "        This method uses the parent classes (Transformer)\n",
    "        .getOrDefault method to get the minimum\n",
    "        size of a token.\n",
    "        \"\"\"\n",
    "        return self.getOrDefault(self.min_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidatorModel\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "def identify_model_type(model_path):\n",
    "    # Check if metadata exists to identify the model type\n",
    "    metadata_path = os.path.join(model_path, 'metadata')\n",
    "    if os.path.exists(metadata_path):\n",
    "        with open(os.path.join(metadata_path, 'part-00000'), 'r') as file:\n",
    "            metadata = json.load(file)\n",
    "            return metadata['class']\n",
    "    else: \n",
    "        try:\n",
    "            model = CrossValidatorModel.load(model_path)\n",
    "            del model\n",
    "            return \"CrossValidatorModel\"\n",
    "        except Exception as e1:\n",
    "            # Try loading the model as PipelineModel\n",
    "            try:\n",
    "                model = PipelineModel.load(model_path)\n",
    "                del model\n",
    "                return \"PipelineModel\"\n",
    "            except Exception as e2:\n",
    "                return \"Unknown model type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:31: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\w'\n",
      "/var/folders/1d/rj0w684n0z533z06yt6wyj2h0000gn/T/ipykernel_54958/41447811.py:31: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  .setCleanupPatterns([\"[^\\w\\d\\s]\"]) # remove punctuations (keep alphanumeric chars)\n"
     ]
    }
   ],
   "source": [
    "# Building the pipeline for nlp transformers\n",
    "from sparknlp.base import *\n",
    "from pyspark.ml import Pipeline\n",
    "from sparknlp.annotator import Tokenizer, DocumentAssembler, StopWordsCleaner, Normalizer, Stemmer\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF, NGram\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "paramGrid = ParamGridBuilder() \n",
    "\n",
    "def get_nlp_pipeline():\n",
    "    documentAssembler = DocumentAssembler()\\\n",
    "        .setInputCol(\"reviewText\")\\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "    stopwords_cleaner = StopWordsCleaner()\\\n",
    "        .setInputCols(\"token\")\\\n",
    "        .setOutputCol(\"cleanTokens\")\\\n",
    "        .setCaseSensitive(False)\n",
    "\n",
    "    tokenizer = Tokenizer() \\\n",
    "        .setInputCols([\"document\"]) \\\n",
    "        .setOutputCol(\"token\")\n",
    "\n",
    "    normalizer = Normalizer() \\\n",
    "        .setInputCols([\"token\"]) \\\n",
    "        .setOutputCol(\"normalized\")\\\n",
    "        .setLowercase(True)\\\n",
    "        .setCleanupPatterns([\"[^\\w\\d\\s]\"]) # remove punctuations (keep alphanumeric chars)\n",
    "    # if we don't set CleanupPatterns, it will only keep alphabet letters ([^A-Za-z])\n",
    " \n",
    "\n",
    "    nlpPipeline = Pipeline(stages=[\n",
    "        documentAssembler, \n",
    "        tokenizer,\n",
    "        stopwords_cleaner\n",
    "    ])\n",
    "    \n",
    "    return nlpPipeline\n",
    "\n",
    "def get_cross_val_pipeline():\n",
    "    bigram2 = NGram(inputCol=\"stemmed\", outputCol=\"bigrams\", n=2)\n",
    "\n",
    "    tf6 = HashingTF(inputCol=\"bigrams\", outputCol=\"rawFeatures\", numFeatures=2e5)\n",
    "\n",
    "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "    lr = LogisticRegression(maxIter=10)\n",
    "\n",
    "    paramGrid = ParamGridBuilder() \\\n",
    "        .addGrid(idf.minDocFreq, [2, 5]) \\\n",
    "        .addGrid(lr.regParam, [0.0, 0.1]) \\\n",
    "        .build()\n",
    "    stemmer = PorterStemming(inputCol=\"token\", outputCol=\"stemmed\")\n",
    " \n",
    "    stemmed_bigram_pipeline = Pipeline(stages=[bigram2, tf6, idf, lr])\n",
    "    return (stemmed_bigram_pipeline, paramGrid, stemmer)\n",
    "\n",
    "def get_crossval_evaluator():\n",
    "    stemmed_bigram_pipeline, paramGrid, stemmer = get_cross_val_pipeline()\n",
    "    crossval = CrossValidator(estimator= stemmed_bigram_pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=BinaryClassificationEvaluator(),\n",
    "                              numFolds=3,\n",
    "                              parallelism=2\n",
    "                              )\n",
    "    return (crossval, stemmer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current line size: 509, Total size: 10485463\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:11:55 WARN TaskSetManager: Stage 6 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    5.0|A0020356UF96ZV361ST|B00MAN6K54|Karma is a bitch ...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:11:58 WARN TaskSetManager: Stage 9 contains a task of very large size (1246 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Karma is a bitch ...|    1|[Karma, bitch, ch...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 0\n",
      "Model type: org.apache.spark.ml.tuning.CrossValidatorModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:05 WARN TaskSetManager: Stage 44 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 489, Total size: 10485356\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0689240FYOX63XMAO3Y|B006YKFYVK|Got it for my 6 M...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Got it for my 6 M...|    1|[Got, 6, Month, t...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 1\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:11 WARN TaskSetManager: Stage 75 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 551, Total size: 10485755\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A100297S0KWNIB|B00GGIN32C|Worked for our pu...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Worked for our pu...|    1|[Worked, purposes...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 2\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:16 WARN TaskSetManager: Stage 106 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 506, Total size: 10485311\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A020433331IIQAID3WSG|B005OH6IPA|Arrived and it is...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Arrived and it is...|    1|[Arrived, right, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 3\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:21 WARN TaskSetManager: Stage 137 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2327, Total size: 10485265\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0980358L4HV4VLJI3QT|B001AQQ4Z8|Good for little kids|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Good for little kids|    1|[Good, little, kids]|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 4\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:26 WARN TaskSetManager: Stage 168 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 325, Total size: 10485706\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A01631062UX24GI4LJKF|B00KY8GAAM|I must say this w...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I must say this w...|    1|[must, say, great...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 5\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:30 WARN TaskSetManager: Stage 199 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1643, Total size: 10484347\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A00463782V7TKAP9EMNL|B00VD1VV58|I love home ethic...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I love home ethic...|    1|[love, home, ethi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 6\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:34 WARN TaskSetManager: Stage 230 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 795, Total size: 10485627\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A10030KC6GYK89|B00028IXC2|I was surprised t...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I was surprised t...|    1|[surprised, find,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 7\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:39 WARN TaskSetManager: Stage 261 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 762, Total size: 10485053\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0403142PTCZBLIH0GEF|B006MCVAJA|Wonderful product...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Wonderful product...|    1|[Wonderful, produ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 8\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:43 WARN TaskSetManager: Stage 292 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 995, Total size: 10485201\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0508493HJ7B5SE6V7TN|B0000AT0WE|Great locking mou...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Great locking mou...|    1|[Great, locking, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 9\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:46 WARN TaskSetManager: Stage 323 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 533, Total size: 10485561\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0415852RV6U7JD8OV9G|B006R9GI2C|I have not used t...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I have not used t...|    1|[used, items, yet...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 10\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:49 WARN TaskSetManager: Stage 354 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1825, Total size: 10484755\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    2.0|A0220159ZRNBTRKLG08H|B00OY5T3OQ|Garbage. Does not...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Garbage. Does not...|    0|[Garbage, ., fit,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 11\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:53 WARN TaskSetManager: Stage 385 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1477, Total size: 10484445\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1021HGM02HIKB|B0002EQTIQ|Perfect for snack...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Perfect for snack...|    1|[Perfect, snackin...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 12\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:56 WARN TaskSetManager: Stage 416 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 506, Total size: 10485558\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    1.0|A0730101XOT31OKVKHYK|B008YFT7BQ|not what i expect...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|not what i expect...|    0|[expected, ,, thi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 13\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:12:59 WARN TaskSetManager: Stage 447 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 643, Total size: 10485171\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0099735VDZ3HDCAAYKL|B00WPVFCHI|This is the begin...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This is the begin...|    1|[beginning, great...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 14\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:02 WARN TaskSetManager: Stage 478 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 433, Total size: 10485746\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0196552RI15HI7JB9PW|B00LNSBID6|Good  product\\nwo...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Good  product\\nwo...|    1|[Good, product, w...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 15\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:06 WARN TaskSetManager: Stage 509 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 973, Total size: 10485493\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A100BB737UMFHX|B0002AQ2LY|Bubble filters do...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Bubble filters do...|    1|[Bubble, filters,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 16\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:09 WARN TaskSetManager: Stage 540 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 630, Total size: 10485632\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0102335OJZYGD6JG8YQ|B00FEA8S2I|Light, rugged. Pr...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Light, rugged. Pr...|    1|[Light, ,, rugged...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 17\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:12 WARN TaskSetManager: Stage 571 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 278, Total size: 10485722\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A101VZZNUTBN9O|B00U1F6TO0|My chihuahua bark...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|My chihuahua bark...|    1|[chihuahua, barks...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 18\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:15 WARN TaskSetManager: Stage 602 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 488, Total size: 10485476\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0595675HTCA2LNAC33A|B00DNJORL8|Not a fan of the ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Not a fan of the ...|    1|[fan, bulk, packa...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 19\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:18 WARN TaskSetManager: Stage 633 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1483, Total size: 10484354\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    1.0|A06900664R2JKVGD4B5I|B00029WRMI|Awful!! Extremely...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Awful!! Extremely...|    0|[Awful, !!, Extre...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 20\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:21 WARN TaskSetManager: Stage 664 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 677, Total size: 10485442\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0122375SQ8Z42DUL03J|B007IRMTXE|Works really well...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Works really well...|    1|[Works, really, w...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 21\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:24 WARN TaskSetManager: Stage 695 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 315, Total size: 10485483\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+----------+---------+\n",
      "|overall|    reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------+----------+----------+---------+\n",
      "|    5.0|A1008A7IPWAN3M|B00S5E5G8Y|    GREAT!|        1|\n",
      "+-------+--------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+----------+\n",
      "|reviewText|label|     token|\n",
      "+----------+-----+----------+\n",
      "|    GREAT!|    1|[GREAT, !]|\n",
      "+----------+-----+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 22\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:28 WARN TaskSetManager: Stage 726 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1032, Total size: 10485048\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0473259F6GQNBD88IYN|B0002KKITG|I've been using s...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I've been using s...|    1|[using, stoner, p...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 23\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:31 WARN TaskSetManager: Stage 757 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 7944, Total size: 10478860\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    1.0|A100WO06OQR8BQ|B00176T5I4|This is a totally...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This is a totally...|    0|[totally, useless...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 24\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:35 WARN TaskSetManager: Stage 788 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 271, Total size: 10485529\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A00463782V7TKAP9EMNL|B01HH7JSW4|This is a wonderf...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This is a wonderf...|    1|[wonderful, compi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 25\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:38 WARN TaskSetManager: Stage 819 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 578, Total size: 10485718\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0994261IXWIKPX087WZ|B00DMPQYHI|This pump has sat...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This pump has sat...|    1|[pump, satisfied,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 26\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:41 WARN TaskSetManager: Stage 850 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 493, Total size: 10485708\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    1.0|A0815414IQ081GR6BB0I|B00QR1U9X4|100% annoying. No...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|100% annoying. No...|    0|[100%, annoying, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 27\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:44 WARN TaskSetManager: Stage 881 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1319, Total size: 10484992\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A1001UHWPK1BIB|B000FFIL60|Not bad. Jasmine ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Not bad. Jasmine ...|    1|[bad, ., Jasmine,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 28\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:47 WARN TaskSetManager: Stage 912 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 331, Total size: 10485492\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A06900664R2JKVGD4B5I|B00T6IXPXG|It's awesome! Jus...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|It's awesome! Jus...|    1|[awesome, !, keep...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 29\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:50 WARN TaskSetManager: Stage 943 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1139, Total size: 10485650\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+---------------+---------+\n",
      "|overall|          reviewerID|      asin|     reviewText|sentiment|\n",
      "+-------+--------------------+----------+---------------+---------+\n",
      "|    5.0|A0980358L4HV4VLJI3QT|B007F8XJMG|Good protection|        1|\n",
      "+-------+--------------------+----------+---------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+---------------+-----+------------------+\n",
      "|     reviewText|label|             token|\n",
      "+---------------+-----+------------------+\n",
      "|Good protection|    1|[Good, protection]|\n",
      "+---------------+-----+------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 30\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:53 WARN TaskSetManager: Stage 974 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3841, Total size: 10484871\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100UXMXYOQU1X|B000WWIPEE|Works great!  You...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Works great!  You...|    1|[Works, great, !,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 31\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:13:56 WARN TaskSetManager: Stage 1005 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 498, Total size: 10485613\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    1.0|A101GDRKHYM662|B0017JASSW|This product prec...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This product prec...|    0|[product, precipi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 32\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:00 WARN TaskSetManager: Stage 1036 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 650, Total size: 10485276\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1012PSARX3LDJ|B00PL54K7I|Great light, has ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Great light, has ...|    1|[Great, light, ,,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 33\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:02 WARN TaskSetManager: Stage 1067 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1080, Total size: 10485188\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A103D6W7TXOLI2|B000NPPB1A|its a small flatb...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|its a small flatb...|    1|[small, flatbar, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 34\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:05 WARN TaskSetManager: Stage 1098 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1080, Total size: 10485339\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A00463782V7TKAP9EMNL|B00BMTQNQ8|Being blind doesn...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Being blind doesn...|    1|[blind, mean, see...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 35\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:08 WARN TaskSetManager: Stage 1129 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 405, Total size: 10485656\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0473259F6GQNBD88IYN|B001T9AFBK|Been using stoner...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Been using stoner...|    1|[using, stoner, p...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 36\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:11 WARN TaskSetManager: Stage 1160 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1160, Total size: 10485336\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    1.0|A01910163UJ08PFOKPI6|B00FURVI6S|I ordered 2 of th...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I ordered 2 of th...|    0|[ordered, 2, time...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 37\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:14 WARN TaskSetManager: Stage 1191 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3470, Total size: 10483922\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    3.0|A1011UZJAELNPL|B0199RSZOC|The only problem ...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|The only problem ...|    0|[problem, story, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 38\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:17 WARN TaskSetManager: Stage 1222 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 597, Total size: 10485444\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    1.0|A102MPY5LHR334|B01C47QGPE|Not comparable to...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Not comparable to...|    0|[comparable, adva...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 39\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:20 WARN TaskSetManager: Stage 1253 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1637, Total size: 10484674\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|overall|          reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|    5.0|A0034986DWR7WEDQN0GV|B000E28MTA| Excellent|        1|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+-----------+\n",
      "|reviewText|label|      token|\n",
      "+----------+-----+-----------+\n",
      "| Excellent|    1|[Excellent]|\n",
      "+----------+-----+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 40\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:24 WARN TaskSetManager: Stage 1284 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 422, Total size: 10485671\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0579792GG3MNILZ71RV|B005C1Y9D6|Honda pilot led l...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Honda pilot led l...|    1|[Honda, pilot, le...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 41\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:27 WARN TaskSetManager: Stage 1315 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 438, Total size: 10485486\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    4.0|A0020356UF96ZV361ST|B00NCRUD0A|You never know wh...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|You never know wh...|    1|[never, know, rea...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 42\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:30 WARN TaskSetManager: Stage 1346 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1247, Total size: 10485355\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0397816ZJHDVVI9IRM1|B000XOLKFW|fits good, missin...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|fits good, missin...|    1|[fits, good, ,, m...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 43\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:32 WARN TaskSetManager: Stage 1377 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 757, Total size: 10485672\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0165490GQW9X6ELEQG8|B00CNIDH7K|Totally Surprised...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Totally Surprised...|    1|[Totally, Surpris...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 44\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:35 WARN TaskSetManager: Stage 1408 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2277, Total size: 10485380\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0122375SQ8Z42DUL03J|B00ZP6HS6S|She checked it ou...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|She checked it ou...|    1|[checked, zipped,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 45\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:38 WARN TaskSetManager: Stage 1439 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1370, Total size: 10484915\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A101C2665VHZ7E|B01AO0GF6I|My child loves th...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|My child loves th...|    1|[child, loves, ki...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 46\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:40 WARN TaskSetManager: Stage 1470 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 722, Total size: 10485725\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0415852RV6U7JD8OV9G|B00E1OSCEM|Necessary for tho...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Necessary for tho...|    1|[Necessary, knit,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 47\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:43 WARN TaskSetManager: Stage 1501 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 475, Total size: 10485322\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0085845UER34CCMXCHL|B0002ARYWU|We've been buying...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|We've been buying...|    1|[buying, jolly, b...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 48\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:46 WARN TaskSetManager: Stage 1532 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 413, Total size: 10485409\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A00463782V7TKAP9EMNL|B00XJZ6LV0|There must be som...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|There must be som...|    1|[must, something,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 49\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:50 WARN TaskSetManager: Stage 1563 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3737, Total size: 10484875\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    3.0|A0289048PRWFY7ZXQKCD|B00WEV4NPG|I've never found ...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I've never found ...|    0|[never, found, re...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 50\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:52 WARN TaskSetManager: Stage 1594 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 395, Total size: 10485491\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    1.0|A101EVFXW8G49L|B00B0FT2T4|I somehow purchas...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I somehow purchas...|    0|[somehow, purchas...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 51\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:55 WARN TaskSetManager: Stage 1625 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 4803, Total size: 10482742\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0862583SGINX9LS6XJ1|B000C32J5O|The only real way...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|The only real way...|    1|[real, way, stop,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 52\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:14:58 WARN TaskSetManager: Stage 1656 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3022, Total size: 10484632\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0178408Z1TQAM7D75FY|B00TVG0LDK|I liked this book...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I liked this book...|    1|[liked, book, ., ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 53\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:01 WARN TaskSetManager: Stage 1687 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 308, Total size: 10485541\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0436342QLT4257JODYJ|B002WYM6NQ|I needed somewher...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I needed somewher...|    1|[needed, somewher...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 54\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:03 WARN TaskSetManager: Stage 1718 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 569, Total size: 10485282\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100MPP98YN1U6|B000GLOFTU|Man, but this sur...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Man, but this sur...|    1|[Man, ,, sure, ki...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 55\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:06 WARN TaskSetManager: Stage 1749 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3670, Total size: 10482104\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|overall|          reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|    5.0|A07461691T3ZPYIJW2MO|B00BW0RGBI|       5/5|        1|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+-----+\n",
      "|reviewText|label|token|\n",
      "+----------+-----+-----+\n",
      "|       5/5|    1|[5/5]|\n",
      "+----------+-----+-----+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 56\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:11 WARN TaskSetManager: Stage 1780 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1255, Total size: 10484650\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|overall|          reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|    5.0|A0731751WJ9S3CJ2X7R3|B019TEM00K| Good book|        1|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+------------+\n",
      "|reviewText|label|       token|\n",
      "+----------+-----+------------+\n",
      "| Good book|    1|[Good, book]|\n",
      "+----------+-----+------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 57\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:14 WARN TaskSetManager: Stage 1811 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 7947, Total size: 10478617\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A00463782V7TKAP9EMNL|B00N992IFY|Rick has everythi...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Rick has everythi...|    1|[Rick, everything...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 58\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:16 WARN TaskSetManager: Stage 1842 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1095, Total size: 10485377\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A00463782V7TKAP9EMNL|B00GG1C83Y|This is a very fu...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This is a very fu...|    1|[fun, read, ,, pa...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 59\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:21 WARN TaskSetManager: Stage 1873 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1175, Total size: 10484997\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    2.0|A0954586PW98I9TNZXJP|B00OUAQAOQ|While this scratc...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|While this scratc...|    0|[scratcher, sturd...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 60\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:25 WARN TaskSetManager: Stage 1904 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 950, Total size: 10485233\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|overall|          reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|    5.0|A07461691T3ZPYIJW2MO|B00BW0RF3W|       5/5|        1|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+-----+\n",
      "|reviewText|label|token|\n",
      "+----------+-----+-----+\n",
      "|       5/5|    1|[5/5]|\n",
      "+----------+-----+-----+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 61\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:28 WARN TaskSetManager: Stage 1935 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 441, Total size: 10485430\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    1.0|A02635363YZWI9MI13CD|B005GLNAFK|to dim and does n...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|to dim and does n...|    0|[dim, fit, need, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 62\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:32 WARN TaskSetManager: Stage 1966 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1189, Total size: 10484928\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    1.0|A0108361NUAPHEN2W129|B006UJGFZY|I have a 10 lb ch...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I have a 10 lb ch...|    0|[10, lb, chi, kno...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 63\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:36 WARN TaskSetManager: Stage 1997 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 446, Total size: 10485704\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    3.0|A100DE0GESG8HY|B004JBB22G|1 out of the 3 pa...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|1 out of the 3 pa...|    0|[1, 3, packs, see...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 64\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:40 WARN TaskSetManager: Stage 2028 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1162, Total size: 10484946\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    4.0|A0020356UF96ZV361ST|B01888QTL4|You can not trust...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|You can not trust...|    1|[trust, anybody, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 65\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:43 WARN TaskSetManager: Stage 2059 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 927, Total size: 10485107\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A00463782V7TKAP9EMNL|B016U3FA8M|Thanksgiving is c...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Thanksgiving is c...|    1|[Thanksgiving, co...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 66\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:47 WARN TaskSetManager: Stage 2090 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 320, Total size: 10485462\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0099735VDZ3HDCAAYKL|B016DX8ZHC|This is my first ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This is my first ...|    1|[first, Black, Hi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 67\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:50 WARN TaskSetManager: Stage 2121 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 407, Total size: 10485404\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100WO06OQR8BQ|B00JFT6JE8|My Dobie is getti...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|My Dobie is getti...|    1|[Dobie, getting, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 68\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:53 WARN TaskSetManager: Stage 2152 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3775, Total size: 10484009\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    5.0|A0743345UFTOA4V1Z7W|B000IAIP72|Haven't used it y...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Haven't used it y...|    1|[used, yet, ., Go...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 69\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:56 WARN TaskSetManager: Stage 2183 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 422, Total size: 10485489\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    2.0|A100DO844MBA4W|B005GSYIV8|I WISH my cat lik...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I WISH my cat lik...|    0|[WISH, cat, liked...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 70\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:15:59 WARN TaskSetManager: Stage 2214 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 955, Total size: 10485471\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0328927TA7ECTIKNP3G|B00BJNDITW|My hero, he can s...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|My hero, he can s...|    1|[hero, ,, seduce,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 71\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:03 WARN TaskSetManager: Stage 2245 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 695, Total size: 10485521\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1031T963BGNRU|B019Y3NCAI|Really incredibly...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Really incredibly...|    1|[Really, incredib...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 72\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:07 WARN TaskSetManager: Stage 2276 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 600, Total size: 10485248\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0527988KUR7884GZD9A|B006CQ1ZHI|The taste is grea...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|The taste is grea...|    1|[taste, great, .,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 73\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:10 WARN TaskSetManager: Stage 2307 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1434, Total size: 10484390\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    3.0|A102LBNR54QVHM|B001VP565M|My dog really lik...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|My dog really lik...|    0|[dog, really, lik...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 74\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:14 WARN TaskSetManager: Stage 2338 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 411, Total size: 10485618\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0787942UFOPVFL0MFMB|B00DSD58DA|Good quality stic...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Good quality stic...|    1|[Good, quality, s...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 75\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:17 WARN TaskSetManager: Stage 2369 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 685, Total size: 10485111\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0769183K7L2H54MJRG4|B0079XPUOW|Clever.  Fun.  Un...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Clever.  Fun.  Un...|    1|[Clever, ., Fun, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 76\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:21 WARN TaskSetManager: Stage 2400 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3514, Total size: 10485581\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A101RGQP89LYZI|B00PBUEQJK|Great book. I rea...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Great book. I rea...|    1|[Great, book, ., ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 77\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:24 WARN TaskSetManager: Stage 2431 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 840, Total size: 10485475\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A00463782V7TKAP9EMNL|B017JAJ5G8|Jason is beset up...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Jason is beset up...|    1|[Jason, beset, up...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 78\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:28 WARN TaskSetManager: Stage 2462 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2509, Total size: 10483618\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A100E61UIJH3B5|B001E3RPKK|Very easy to keep...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Very easy to keep...|    1|[easy, keep, clea...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 79\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:31 WARN TaskSetManager: Stage 2493 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2806, Total size: 10483307\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A101U7FNC994O3|B00NNDXT68|The way the book ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|The way the book ...|    1|[way, book, start...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 80\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:34 WARN TaskSetManager: Stage 2524 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1696, Total size: 10484679\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A00463782V7TKAP9EMNL|B00L5AYW3A|Is Javier really ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Is Javier really ...|    1|[Javier, really, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 81\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:37 WARN TaskSetManager: Stage 2555 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 346, Total size: 10485565\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    1.0|A07716593573L93RJQ1E|B00FRI5TMY|Nice, if it worke...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Nice, if it worke...|    0|[Nice, ,, worked,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 82\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:40 WARN TaskSetManager: Stage 2586 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 408, Total size: 10485538\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1017UZIPW58F4|B00F6PAPUO|Shipping took for...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Shipping took for...|    1|[Shipping, took, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 83\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:44 WARN TaskSetManager: Stage 2617 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 5376, Total size: 10485415\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0620511OK30N45S3WVF|B0002YX7MM|This was the best...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This was the best...|    1|[best, price, far...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 84\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:50 WARN TaskSetManager: Stage 2648 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 660, Total size: 10485404\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0099735VDZ3HDCAAYKL|B016B636SO|5+++++ Stars this...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|5+++++ Stars this...|    1|[5+++++, Stars, o...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 85\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:53 WARN TaskSetManager: Stage 2679 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1826, Total size: 10484798\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100DFH9N1KS7T|B00NFSM49Y|This music lifts ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+-----------------+\n",
      "|          reviewText|label|            token|\n",
      "+--------------------+-----+-----------------+\n",
      "|This music lifts ...|    1|[music, lifts, .]|\n",
      "+--------------------+-----+-----------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 86\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:16:56 WARN TaskSetManager: Stage 2710 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 341, Total size: 10485563\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0496269KM4VQ5JO5KRY|B00FFC9QSK|What can I say I ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|What can I say I ...|    1|[say, Love, Kinnc...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 87\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:00 WARN TaskSetManager: Stage 2741 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 446, Total size: 10485677\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A01631062UX24GI4LJKF|B00OQI625O|This was so good....|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This was so good....|    1|[good, ., Every, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 88\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:03 WARN TaskSetManager: Stage 2772 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 303, Total size: 10485493\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    3.0|A1017T4YMQMZ1X|B000E8UR24|I was not able to...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I was not able to...|    0|[able, try, fauce...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 89\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:06 WARN TaskSetManager: Stage 2803 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 361, Total size: 10485571\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "|overall|          reviewerID|      asin|  reviewText|sentiment|\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "|    4.0|A0096681Y127OL1H8W3U|B000HHNYHW|good product|        1|\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+------------+-----+---------------+\n",
      "|  reviewText|label|          token|\n",
      "+------------+-----+---------------+\n",
      "|good product|    1|[good, product]|\n",
      "+------------+-----+---------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 90\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:09 WARN TaskSetManager: Stage 2834 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1401, Total size: 10484958\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0024936S1WI02OHH9DP|B016AG5DR2|Looks great fits ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Looks great fits ...|    1|[Looks, great, fi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 91\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:12 WARN TaskSetManager: Stage 2865 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1638, Total size: 10485270\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A047816347FS2EFQ6VEY|B007X93M4C|Book has simple r...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Book has simple r...|    1|[Book, simple, re...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 92\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:16 WARN TaskSetManager: Stage 2896 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 315, Total size: 10485719\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0944456Z3LN62I2DT3O|B01C7QAK7C|Works perfect and...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Works perfect and...|    1|[Works, perfect, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 93\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:19 WARN TaskSetManager: Stage 2927 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 554, Total size: 10485297\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0473259F6GQNBD88IYN|B000C9NA8S|Bought this canis...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Bought this canis...|    1|[Bought, canister...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 94\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:23 WARN TaskSetManager: Stage 2958 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 793, Total size: 10485270\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100I8XXUFVRCM|B00WZ8WDTG|Top quality but m...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Top quality but m...|    1|[Top, quality, do...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 95\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:26 WARN TaskSetManager: Stage 2989 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 814, Total size: 10485665\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+------------------+---------+\n",
      "|overall|          reviewerID|      asin|        reviewText|sentiment|\n",
      "+-------+--------------------+----------+------------------+---------+\n",
      "|    5.0|A0629255VPARUWJZM5XI|B009IISLLU|Good solid product|        1|\n",
      "+-------+--------------------+----------+------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+------------------+-----+--------------------+\n",
      "|        reviewText|label|               token|\n",
      "+------------------+-----+--------------------+\n",
      "|Good solid product|    1|[Good, solid, pro...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 96\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:30 WARN TaskSetManager: Stage 3020 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 4444, Total size: 10482151\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0926538LGZ1P4CJAQO2|B00WSJXJE0|This got 5 stars ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This got 5 stars ...|    1|[got, 5, stars, s...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 97\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:33 WARN TaskSetManager: Stage 3051 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 6299, Total size: 10480938\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0968684PHO6YBBM3WA6|B00H1NNFTW|Looks good on my ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Looks good on my ...|    1|[Looks, good, 22r...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 98\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:36 WARN TaskSetManager: Stage 3082 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1246, Total size: 10485639\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A108B8OUQ0GHNF|B001T4FGS2|Great file handle...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Great file handle...|    1|[Great, file, han...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 99\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:38 WARN TaskSetManager: Stage 3113 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 298, Total size: 10485622\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    4.0|A0807760H1KAYIBFPIS|B00FA61KNU|Well I enjoyed th...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Well I enjoyed th...|    1|[Well, enjoyed, s...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 100\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:41 WARN TaskSetManager: Stage 3144 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 5859, Total size: 10485529\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0705654XT5UCAYOY7TH|B00F94YP8A|Delicious! So but...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Delicious! So but...|    1|[Delicious, !, bu...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 101\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:44 WARN TaskSetManager: Stage 3175 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2902, Total size: 10485122\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A1019XHLIPLYCD|B001Q3KUAK|My daughter got t...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|My daughter got t...|    1|[daughter, got, j...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 102\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:46 WARN TaskSetManager: Stage 3206 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 735, Total size: 10485664\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    2.0|A100GL2NQS0533|B00DTEZZ9A|Only 3 stars caus...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Only 3 stars caus...|    0|[3, stars, cause,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 103\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:49 WARN TaskSetManager: Stage 3237 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 316, Total size: 10485491\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100WO06OQR8BQ|B0093J41PE|Walnuts are one o...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Walnuts are one o...|    1|[Walnuts, one, fa...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 104\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:51 WARN TaskSetManager: Stage 3268 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 349, Total size: 10485583\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A101DH2EE0D7P4|B00BGS31MO|Works well I gues...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Works well I gues...|    1|[Works, well, gue...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 105\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:54 WARN TaskSetManager: Stage 3299 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 629, Total size: 10485712\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    3.0|A0262876TDA2EYEV3LVJ|B00IPCOVTG|My bunny loves th...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|My bunny loves th...|    0|[bunny, loves, fi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 106\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:57 WARN TaskSetManager: Stage 3330 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 581, Total size: 10485232\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0099735VDZ3HDCAAYKL|B00GJCNLWC|This was a very e...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This was a very e...|    1|[exciting, book, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 107\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:17:59 WARN TaskSetManager: Stage 3361 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 528, Total size: 10485565\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A102NKLXRT5KEM|B0044UZSPY|My Vet recommende...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|My Vet recommende...|    1|[Vet, recommended...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 108\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:02 WARN TaskSetManager: Stage 3392 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 354, Total size: 10485725\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|overall|          reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|    2.0|A0225879AOG5GLHAB7EH|B000MCICC4|       ok.|        0|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+-------+\n",
      "|reviewText|label|  token|\n",
      "+----------+-----+-------+\n",
      "|       ok.|    0|[ok, .]|\n",
      "+----------+-----+-------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 109\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:05 WARN TaskSetManager: Stage 3423 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 290, Total size: 10485612\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0102335OJZYGD6JG8YQ|B01BLEWFGK|Even not covering...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Even not covering...|    1|[Even, covering, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 110\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:09 WARN TaskSetManager: Stage 3454 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 274, Total size: 10485729\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100ELBI8BSXR1|B00006IX59|WATCH THOSE TENNI...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|WATCH THOSE TENNI...|    1|[WATCH, TENNIS, B...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 111\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:13 WARN TaskSetManager: Stage 3485 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1346, Total size: 10485680\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0486341RMMNBBGS1G4X|B01489LL4M|Perfect for our b...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Perfect for our b...|    1|[Perfect, barnyar...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 112\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:16 WARN TaskSetManager: Stage 3516 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2275, Total size: 10485576\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0362231G0D49Y5H52ES|B0000302V3|works as advertis...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|works as advertis...|    1|[works, advertise...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 113\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:19 WARN TaskSetManager: Stage 3547 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1163, Total size: 10484813\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0323662LGDA74F87HNI|B00SQK9GZQ|Yes, double faced...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Yes, double faced...|    1|[Yes, ,, double, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 114\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:22 WARN TaskSetManager: Stage 3578 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 492, Total size: 10485539\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A10030KC6GYK89|B00D63QTAI|Good story, a lit...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Good story, a lit...|    1|[Good, story, ,, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 115\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:25 WARN TaskSetManager: Stage 3609 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 461, Total size: 10485484\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0191512Q2Z9IPUAE2RZ|B00A97FIG0|Used a Trane Weat...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Used a Trane Weat...|    1|[Used, Trane, Wea...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 116\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:28 WARN TaskSetManager: Stage 3640 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 596, Total size: 10485517\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A10002EO9ZUY0B|B0017R5UIW|a step forward fo...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|a step forward fo...|    1|[step, forward, m...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 117\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:34 WARN TaskSetManager: Stage 3671 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1630, Total size: 10485421\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0539606PFOMM461E03I|B00MN9DNNW|Lights aren't the...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Lights aren't the...|    1|[Lights, best, ,,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 118\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:37 WARN TaskSetManager: Stage 3702 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 432, Total size: 10485543\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0096681Y127OL1H8W3U|B006ZRUKHK|use it to rust pr...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|use it to rust pr...|    1|[use, rust, proof...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 119\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:40 WARN TaskSetManager: Stage 3733 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3331, Total size: 10482491\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A00463782V7TKAP9EMNL|B01DH1XXG6|Just as the lates...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Just as the lates...|    1|[latest, presiden...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 120\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:46 WARN TaskSetManager: Stage 3764 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2550, Total size: 10485637\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    3.0|A0671524HJIZUG70O7CE|B01EJL2S2S|Worked ok in fron...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Worked ok in fron...|    0|[Worked, ok, fron...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 121\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:49 WARN TaskSetManager: Stage 3795 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 878, Total size: 10485133\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0232309XTWAG6FEGW93|B00CCC281S|A beautiful littl...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|A beautiful littl...|    1|[beautiful, littl...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 122\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:52 WARN TaskSetManager: Stage 3826 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 418, Total size: 10485402\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A00201164H8T5GSBKYFP|B0000025HU|What I like, is v...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|What I like, is v...|    1|[like, ,, good, f...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 123\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:18:56 WARN TaskSetManager: Stage 3857 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2352, Total size: 10484457\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100WO06OQR8BQ|B0062ADT6E|I had installed o...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I had installed o...|    1|[installed, one, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 124\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:00 WARN TaskSetManager: Stage 3888 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 441, Total size: 10485458\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A07936821FOVJO6NP4Q8|B0037UUO60|Had one of these ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Had one of these ...|    1|[one, aircraft, m...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 125\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:02 WARN TaskSetManager: Stage 3919 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 553, Total size: 10485427\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+-----------+---------+\n",
      "|overall|    reviewerID|      asin| reviewText|sentiment|\n",
      "+-------+--------------+----------+-----------+---------+\n",
      "|    5.0|A100JY2S79BBM6|B00K9BFKNM|Great value|        1|\n",
      "+-------+--------------+----------+-----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+-----------+-----+--------------+\n",
      "| reviewText|label|         token|\n",
      "+-----------+-----+--------------+\n",
      "|Great value|    1|[Great, value]|\n",
      "+-----------+-----+--------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 126\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:07 WARN TaskSetManager: Stage 3950 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 606, Total size: 10485407\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A103KNDW8GN92L|B000002PCT|\"Pretzel Logic\", ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|\"Pretzel Logic\", ...|    1|[\", Pretzel, Logi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 127\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:12 WARN TaskSetManager: Stage 3981 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 928, Total size: 10485063\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0886097YX1F6V4PD6J7|B00PHAEFVS|it can not end th...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|it can not end th...|    1|[end, book, 4, Za...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 128\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:15 WARN TaskSetManager: Stage 4012 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 261, Total size: 10485700\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100WO06OQR8BQ|B00FWUTRBQ|I tried to find t...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I tried to find t...|    1|[tried, find, fro...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 129\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:18 WARN TaskSetManager: Stage 4043 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 344, Total size: 10485736\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|overall|          reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|    5.0|A0526222H977CBZM4DK7|B0039QXWPM| EXCELLENT|        1|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+-----------+\n",
      "|reviewText|label|      token|\n",
      "+----------+-----+-----------+\n",
      "| EXCELLENT|    1|[EXCELLENT]|\n",
      "+----------+-----+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 130\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:22 WARN TaskSetManager: Stage 4074 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 595, Total size: 10485647\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    5.0|A0807760H1KAYIBFPIS|B00PB64194|I am in love with...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I am in love with...|    1|[love, characters...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 131\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:25 WARN TaskSetManager: Stage 4105 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2669, Total size: 10484383\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+-----------+---------+\n",
      "|overall|          reviewerID|      asin| reviewText|sentiment|\n",
      "+-------+--------------------+----------+-----------+---------+\n",
      "|    4.0|A0441818S7W7N4A7QL55|B018VLH7D2|As expected|        1|\n",
      "+-------+--------------------+----------+-----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+-----------+-----+----------+\n",
      "| reviewText|label|     token|\n",
      "+-----------+-----+----------+\n",
      "|As expected|    1|[expected]|\n",
      "+-----------+-----+----------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 132\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:28 WARN TaskSetManager: Stage 4136 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1284, Total size: 10485612\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A01631062UX24GI4LJKF|B00HI4V5FU|I have to admit I...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I have to admit I...|    1|[admit, gonna, bu...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 133\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:31 WARN TaskSetManager: Stage 4167 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 704, Total size: 10485171\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A00463782V7TKAP9EMNL|B017KQTTIK|PTSD is a horribl...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|PTSD is a horribl...|    1|[PTSD, horrible, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 134\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:34 WARN TaskSetManager: Stage 4198 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 693, Total size: 10485314\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0610173AX4RY4WQ9LR7|B000YFUQ7I|Got it for the gr...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Got it for the gr...|    1|[Got, grandson, t...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 135\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:37 WARN TaskSetManager: Stage 4229 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 395, Total size: 10485365\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    3.0|A1007QP6OB28XH|B005WZQJV2|Ok bulbs but not ...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Ok bulbs but not ...|    0|[Ok, bulbs, blue,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 136\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:40 WARN TaskSetManager: Stage 4260 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 541, Total size: 10485316\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A00408825PVJW7GFLEGU|B005DL8NJG|good shampoo, cat...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|good shampoo, cat...|    1|[good, shampoo, ,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 137\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:44 WARN TaskSetManager: Stage 4291 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3467, Total size: 10482614\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "|overall|          reviewerID|      asin|  reviewText|sentiment|\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "|    1.0|A0988845PBOUFQEW351Q|B005CHHZH2|Bubbles easy|        0|\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+------------+-----+---------------+\n",
      "|  reviewText|label|          token|\n",
      "+------------+-----+---------------+\n",
      "|Bubbles easy|    0|[Bubbles, easy]|\n",
      "+------------+-----+---------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 138\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:48 WARN TaskSetManager: Stage 4322 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 341, Total size: 10485568\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A10284FAGR5CGT|B000C5GAQQ|Perfect fit. Thes...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Perfect fit. Thes...|    1|[Perfect, fit, .,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 139\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:51 WARN TaskSetManager: Stage 4353 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1350, Total size: 10484689\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    2.0|A10063PJ5C9WQQ|B000GAS2WW|wanted this to co...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|wanted this to co...|    0|[wanted, control,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 140\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:54 WARN TaskSetManager: Stage 4384 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 383, Total size: 10485628\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    3.0|A0980592Q6W60Q720SET|B00K43543Q|For some reason I...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|For some reason I...|    0|[reason, hard, ha...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 141\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:19:59 WARN TaskSetManager: Stage 4415 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1871, Total size: 10485622\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0598317G3T7URZAR3W3|B0024E6QX0|I bought these to...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I bought these to...|    1|[bought, save, ru...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 142\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:02 WARN TaskSetManager: Stage 4446 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 310, Total size: 10485531\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0205727NVAUDXS07YYO|B00OEXP0UE|Just love these. ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Just love these. ...|    1|[love, ., Excelle...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 143\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:04 WARN TaskSetManager: Stage 4477 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 626, Total size: 10485499\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A03056324Y8DG2MLJQJU|B00P0D4V8Y|4.5 stars <3\\n\\nT...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|4.5 stars <3\\n\\nT...|    1|[4.5, stars, <3, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 144\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:07 WARN TaskSetManager: Stage 4508 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 832, Total size: 10485028\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    3.0|A0015332H21AK8WZ0ZCS|B005FTN30U|My 2 have not sho...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|My 2 have not sho...|    0|[2, shown, intere...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 145\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:10 WARN TaskSetManager: Stage 4539 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1367, Total size: 10485218\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+----------+---------+\n",
      "|overall|          reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|    5.0|A0024836TBQJ1WBE4VDY|B00BZ3DDYG|      nice|        1|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+------+\n",
      "|reviewText|label| token|\n",
      "+----------+-----+------+\n",
      "|      nice|    1|[nice]|\n",
      "+----------+-----+------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 146\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:16 WARN TaskSetManager: Stage 4570 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1150, Total size: 10485162\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    3.0|A0856409EA8IMJ9T1VUW|B01AR61DLG|Case is solid blu...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Case is solid blu...|    0|[Case, solid, blu...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 147\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:18 WARN TaskSetManager: Stage 4601 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1446, Total size: 10485638\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0099735VDZ3HDCAAYKL|B01DV4HTFK|I love this serie...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I love this serie...|    1|[love, series, .,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 148\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:21 WARN TaskSetManager: Stage 4632 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 8242, Total size: 10480280\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    5.0|A0667922P09C0VQOKCB|B00AR9F5HC|Great cut out Cam...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Great cut out Cam...|    1|[Great, cut, Came...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 149\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:26 WARN TaskSetManager: Stage 4663 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1253, Total size: 10484706\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0015332H21AK8WZ0ZCS|B005G030TC|These collars are...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|These collars are...|    1|[collars, actuall...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 150\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:29 WARN TaskSetManager: Stage 4694 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 706, Total size: 10485594\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0099735VDZ3HDCAAYKL|B00O27QJIE|The Timber Valley...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|The Timber Valley...|    1|[Timber, Valley, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 151\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:33 WARN TaskSetManager: Stage 4725 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 583, Total size: 10485742\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A101P2KHWCU0G6|B000VK4K3W|Unfortunately, I ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Unfortunately, I ...|    1|[Unfortunately, ,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 152\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:37 WARN TaskSetManager: Stage 4756 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1351, Total size: 10484887\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0178408Z1TQAM7D75FY|B01BLX4CN0|I received this b...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I received this b...|    1|[received, book, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 153\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:41 WARN TaskSetManager: Stage 4787 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2369, Total size: 10485102\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+-------------+---------+\n",
      "|overall|          reviewerID|      asin|   reviewText|sentiment|\n",
      "+-------+--------------------+----------+-------------+---------+\n",
      "|    5.0|A0001528BGUBOEVR6T5U|B0002APLYI|super nice...|        1|\n",
      "+-------+--------------------+----------+-------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+-------------+-----+------------------+\n",
      "|   reviewText|label|             token|\n",
      "+-------------+-----+------------------+\n",
      "|super nice...|    1|[super, nice, ...]|\n",
      "+-------------+-----+------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 154\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:44 WARN TaskSetManager: Stage 4818 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1011, Total size: 10484892\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|overall|          reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|    5.0|A0008898NGEXICE0F146|B00FXIFBLC|  Like!!!!|        1|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+------------+\n",
      "|reviewText|label|       token|\n",
      "+----------+-----+------------+\n",
      "|  Like!!!!|    1|[Like, !!!!]|\n",
      "+----------+-----+------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 155\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:47 WARN TaskSetManager: Stage 4849 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 414, Total size: 10485480\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100WHZANWTAV4|B00F2MQ410|My son absolutely...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|My son absolutely...|    1|[son, absolutely,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 156\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:50 WARN TaskSetManager: Stage 4880 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 284, Total size: 10485542\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A102D7NPKXXS5F|B00473PVVO|Best I ever taste...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Best I ever taste...|    1|[Best, ever, tast...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 157\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:55 WARN TaskSetManager: Stage 4911 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 558, Total size: 10485456\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    4.0|A0020356UF96ZV361ST|B00LU32E1Y|This chick has me...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This chick has me...|    1|[chick, mental, p...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 158\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:20:58 WARN TaskSetManager: Stage 4942 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2954, Total size: 10484054\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A01189826IYDD95102EY|B0009IBJAS|They work great ....|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|They work great ....|    1|[work, great, ., ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 159\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:01 WARN TaskSetManager: Stage 4973 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 5112, Total size: 10483174\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A00463782V7TKAP9EMNL|B00WJ2OJMM|This was a beauti...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This was a beauti...|    1|[beautiful, story...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 160\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:05 WARN TaskSetManager: Stage 5004 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3137, Total size: 10485507\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+------------+---------+\n",
      "|overall|    reviewerID|      asin|  reviewText|sentiment|\n",
      "+-------+--------------+----------+------------+---------+\n",
      "|    5.0|A102FEF1WMFWW4|B000LNVWAI|Works great.|        1|\n",
      "+-------+--------------+----------+------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+------------+-----+-----------------+\n",
      "|  reviewText|label|            token|\n",
      "+------------+-----+-----------------+\n",
      "|Works great.|    1|[Works, great, .]|\n",
      "+------------+-----+-----------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 161\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:08 WARN TaskSetManager: Stage 5035 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1790, Total size: 10485553\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "|overall|          reviewerID|      asin|  reviewText|sentiment|\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "|    5.0|A00222906VX8GH7X6J6B|B001US4DOK|good quality|        1|\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+------------+-----+---------------+\n",
      "|  reviewText|label|          token|\n",
      "+------------+-----+---------------+\n",
      "|good quality|    1|[good, quality]|\n",
      "+------------+-----+---------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 162\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:12 WARN TaskSetManager: Stage 5066 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 999, Total size: 10485230\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0178408Z1TQAM7D75FY|B00RCIBC8C|This was a great ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This was a great ...|    1|[great, book,I, e...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 163\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:15 WARN TaskSetManager: Stage 5097 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 918, Total size: 10485002\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A007125785FZVNMYL9Q1|B000CIGE96|Easy install on m...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Easy install on m...|    1|[Easy, install, 8...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 164\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:18 WARN TaskSetManager: Stage 5128 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1781, Total size: 10485618\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    2.0|A0001528BGUBOEVR6T5U|B00EOEDJ9W|Not stable. Had t...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Not stable. Had t...|    0|[stable, ., retur...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 165\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:23 WARN TaskSetManager: Stage 5159 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 448, Total size: 10485368\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    2.0|A0441396WX3GNL93BT38|B00S9Y0CDY|It's not big like...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|It's not big like...|    0|[big, like, thoug...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 166\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:26 WARN TaskSetManager: Stage 5190 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1488, Total size: 10484779\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0718784TOWF9DX1DOFD|B01FL4AYUK|Easy to put on an...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Easy to put on an...|    1|[Easy, put, take,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 167\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:29 WARN TaskSetManager: Stage 5221 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1215, Total size: 10485743\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1000CJRHLJGY3|B0002F66HY|Spare tire cover ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Spare tire cover ...|    1|[Spare, tire, cov...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 168\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:32 WARN TaskSetManager: Stage 5252 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 818, Total size: 10485422\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    1.0|A0241327M3OM2YQZ0Z8B|B007PV1Z42|Looks great but h...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Looks great but h...|    0|[Looks, great, ab...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 169\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:35 WARN TaskSetManager: Stage 5283 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 346, Total size: 10485647\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "|overall|          reviewerID|      asin|  reviewText|sentiment|\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "|    5.0|A0242421UVUJ5VDYGSLB|B01H2E82MO|Nice product|        1|\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+---------------+\n",
      "|  reviewText|label|          token|\n",
      "+------------+-----+---------------+\n",
      "|Nice product|    1|[Nice, product]|\n",
      "+------------+-----+---------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 170\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:40 WARN TaskSetManager: Stage 5314 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 538, Total size: 10485665\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0096681Y127OL1H8W3U|B000084F45|dogs said ummmmmm...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|dogs said ummmmmm...|    1|[dogs, said, ummm...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 171\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:43 WARN TaskSetManager: Stage 5345 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1595, Total size: 10485028\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0579792GG3MNILZ71RV|B0069TND14|I purchased based...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I purchased based...|    1|[purchased, based...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 172\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:46 WARN TaskSetManager: Stage 5376 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2760, Total size: 10483439\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0539606PFOMM461E03I|B007FSN2UK|Awesome product. ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Awesome product. ...|    1|[Awesome, product...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 173\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:49 WARN TaskSetManager: Stage 5407 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 479, Total size: 10485665\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0163982I33BFLFLDW0T|B001DKRGLM|using it like I s...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|using it like I s...|    1|[using, like, wor...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 174\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:51 WARN TaskSetManager: Stage 5438 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 292, Total size: 10485689\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    1.0|A0710029OTHLNPXF58B3|B0140KUUUK|Broke the first t...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Broke the first t...|    0|[Broke, first, ti...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 175\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:55 WARN TaskSetManager: Stage 5469 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2331, Total size: 10484618\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100E61UIJH3B5|B001E3RPKK|I had a very larg...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I had a very larg...|    1|[large, dog, grea...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 176\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:21:57 WARN TaskSetManager: Stage 5500 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 326, Total size: 10485587\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0595675HTCA2LNAC33A|B00P6P4C30|Bought this for m...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Bought this for m...|    1|[Bought, daughter...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 177\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:02 WARN TaskSetManager: Stage 5531 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2407, Total size: 10484259\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A007125785FZVNMYL9Q1|B004K23IP8|Has worked as des...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Has worked as des...|    1|[worked, designed...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 178\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:05 WARN TaskSetManager: Stage 5562 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1204, Total size: 10485549\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1031HVG5I7I7F|B01C83KB1E|This is a quality...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This is a quality...|    1|[quality, product...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 179\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:08 WARN TaskSetManager: Stage 5593 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2543, Total size: 10484653\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    2.0|A1002UBC6V258U|B00JOVJCI2|It is much larger...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|It is much larger...|    0|[much, larger, ex...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 180\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:13 WARN TaskSetManager: Stage 5624 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1560, Total size: 10484605\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100IC7JRCQDUD|B000X9EDD8|This light works ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This light works ...|    1|[light, works, we...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 181\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:16 WARN TaskSetManager: Stage 5655 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 651, Total size: 10485600\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0441818S7W7N4A7QL55|B006O6EH4Y|Granddaughter lov...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Granddaughter lov...|    1|[Granddaughter, l...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 182\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:19 WARN TaskSetManager: Stage 5686 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 747, Total size: 10485674\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0240447UBWOLI8KGOGT|B008CTBK7S|I bought this pro...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I bought this pro...|    1|[bought, product,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 183\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:22 WARN TaskSetManager: Stage 5717 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 678, Total size: 10485683\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A101XQIAMYU3X1|B005VEWAN0|I agree with a re...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I agree with a re...|    1|[agree, review, s...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 184\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:25 WARN TaskSetManager: Stage 5748 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 609, Total size: 10485226\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0178408Z1TQAM7D75FY|B01EKOGPIM|This book was giv...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This book was giv...|    1|[book, given, aut...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 185\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:27 WARN TaskSetManager: Stage 5779 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 977, Total size: 10485750\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100T19LDH0GGN|B000002P7Z|A fantastically t...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|A fantastically t...|    1|[fantastically, t...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 186\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:30 WARN TaskSetManager: Stage 5810 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 346, Total size: 10485417\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    2.0|A00201164H8T5GSBKYFP|B00914JWSW|I do not like is ...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I do not like is ...|    0|[like, thing, ., ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 187\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:34 WARN TaskSetManager: Stage 5841 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2948, Total size: 10483536\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100WO06OQR8BQ|B0058PBVQY|This is my first ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This is my first ...|    1|[first, experienc...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 188\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:37 WARN TaskSetManager: Stage 5872 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2288, Total size: 10484005\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0281074R0QWE993EX2F|B00H3QRW6E|I absolutely LOVE...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I absolutely LOVE...|    1|[absolutely, LOVE...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 189\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:40 WARN TaskSetManager: Stage 5903 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1428, Total size: 10484446\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    1.0|A0352185LEEL6G01JJXG|B007Y2PMJQ|This was so hard ...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This was so hard ...|    0|[hard, get, found...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 190\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:45 WARN TaskSetManager: Stage 5934 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 911, Total size: 10485173\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A00463782V7TKAP9EMNL|B00O9418Q8|A relationship wh...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|A relationship wh...|    1|[relationship, be...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 191\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:50 WARN TaskSetManager: Stage 5965 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1032, Total size: 10485404\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100WO06OQR8BQ|B01CKCF4QU|I have been satis...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I have been satis...|    1|[satisfied, Promi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 192\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:53 WARN TaskSetManager: Stage 5996 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2023, Total size: 10484025\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A035230154WEA8JCP8HS|B00SC0CPUS|Well she has done...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Well she has done...|    1|[Well, done, ., A...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 193\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:56 WARN TaskSetManager: Stage 6027 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 598, Total size: 10485601\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0980592Q6W60Q720SET|B00NNEIL0Q|One of my favorit...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|One of my favorit...|    1|[One, favorite, b...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 194\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:22:59 WARN TaskSetManager: Stage 6058 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 271, Total size: 10485738\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+---------------+---------+\n",
      "|overall|          reviewerID|      asin|     reviewText|sentiment|\n",
      "+-------+--------------------+----------+---------------+---------+\n",
      "|    5.0|A05467882E05R82HOCOI|B000002K9G|This was a gift|        1|\n",
      "+-------+--------------------+----------+---------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+---------------+-----+------+\n",
      "|     reviewText|label| token|\n",
      "+---------------+-----+------+\n",
      "|This was a gift|    1|[gift]|\n",
      "+---------------+-----+------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 195\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:02 WARN TaskSetManager: Stage 6089 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 329, Total size: 10485633\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A10063PJ5C9WQQ|B01018CVM0|Works well.  I re...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Works well.  I re...|    1|[Works, well, ., ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 196\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:06 WARN TaskSetManager: Stage 6120 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2293, Total size: 10483473\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1017UZIPW58F4|B00ND6R1QE|This was a dark, ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This was a dark, ...|    1|[dark, ,, sensual...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 197\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:09 WARN TaskSetManager: Stage 6151 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2291, Total size: 10485077\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+-------------+---------+\n",
      "|overall|          reviewerID|      asin|   reviewText|sentiment|\n",
      "+-------+--------------------+----------+-------------+---------+\n",
      "|    5.0|A0001528BGUBOEVR6T5U|B0081XII0W|super nice...|        1|\n",
      "+-------+--------------------+----------+-------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+-------------+-----+------------------+\n",
      "|   reviewText|label|             token|\n",
      "+-------------+-----+------------------+\n",
      "|super nice...|    1|[super, nice, ...]|\n",
      "+-------------+-----+------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 198\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:12 WARN TaskSetManager: Stage 6182 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 395, Total size: 10485676\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1063J042DW8P0|B00NQNOFKE|Amazing price for...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Amazing price for...|    1|[Amazing, price, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 199\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:15 WARN TaskSetManager: Stage 6213 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1407, Total size: 10485004\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A101F4ELO07JKH|B00YXQM1DQ|Installed on my 2...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Installed on my 2...|    1|[Installed, 2016,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 200\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:18 WARN TaskSetManager: Stage 6244 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1726, Total size: 10485423\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1039ADUZSJCKR|B004GFPFBO|He looks just lik...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|He looks just lik...|    1|[looks, like, pic...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 201\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:22 WARN TaskSetManager: Stage 6275 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3439, Total size: 10484085\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    4.0|A0020356UF96ZV361ST|B01ENUVJ2A|When you are the ...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|When you are the ...|    1|[boss, drug, empi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 202\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:25 WARN TaskSetManager: Stage 6306 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 775, Total size: 10485652\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0673442VROY91O08DED|B00FY2O7M6|the paint is thin...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|the paint is thin...|    1|[paint, thinner, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 203\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:28 WARN TaskSetManager: Stage 6337 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 499, Total size: 10485350\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A03622674FSWUX0PXPAK|B0000DD7LB|An amazing album ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|An amazing album ...|    1|[amazing, album, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 204\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:31 WARN TaskSetManager: Stage 6368 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 428, Total size: 10485681\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0182108CPDLPRCXQUZQ|B00ABY8WVO|Wish it was bigge...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Wish it was bigge...|    1|[Wish, bigger, ,,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 205\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:37 WARN TaskSetManager: Stage 6399 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 440, Total size: 10485731\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+------------------+---------+\n",
      "|overall|          reviewerID|      asin|        reviewText|sentiment|\n",
      "+-------+--------------------+----------+------------------+---------+\n",
      "|    5.0|A0435798X3P8Z8IZW64R|B00520DQJ0|What I expected...|        1|\n",
      "+-------+--------------------+----------+------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+------------------+-----+---------------+\n",
      "|        reviewText|label|          token|\n",
      "+------------------+-----+---------------+\n",
      "|What I expected...|    1|[expected, ...]|\n",
      "+------------------+-----+---------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 206\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:40 WARN TaskSetManager: Stage 6430 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1121, Total size: 10485255\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0122375SQ8Z42DUL03J|B00TZI3Q7M|My cat has been v...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|My cat has been v...|    1|[cat, vomiting, d...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 207\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:44 WARN TaskSetManager: Stage 6461 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1077, Total size: 10485097\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0099735VDZ3HDCAAYKL|B00KVQZSF0|Hot Hot Hot. If y...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Hot Hot Hot. If y...|    1|[Hot, Hot, Hot, ....|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 208\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:48 WARN TaskSetManager: Stage 6492 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 566, Total size: 10485222\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    3.0|A0968684PHO6YBBM3WA6|B00842A7F4|You get what you ...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+----------------+\n",
      "|          reviewText|label|           token|\n",
      "+--------------------+-----+----------------+\n",
      "|You get what you ...|    0|[get, pay, ....]|\n",
      "+--------------------+-----+----------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 209\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:52 WARN TaskSetManager: Stage 6523 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 985, Total size: 10484880\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A08161909WK3HU7UYTMW|B000EZ8E72|Well i would advi...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Well i would advi...|    1|[Well, advise, tr...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 210\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:55 WARN TaskSetManager: Stage 6554 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 513, Total size: 10485651\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A007917716EGEEP4D8LB|B00ZW65HQO|To start off I di...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|To start off I di...|    1|[start, blow, fus...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 211\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:23:58 WARN TaskSetManager: Stage 6585 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 644, Total size: 10485482\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A01631062UX24GI4LJKF|B00QBFEV6M|Awesome read. Lov...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Awesome read. Lov...|    1|[Awesome, read, ....|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 212\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:00 WARN TaskSetManager: Stage 6616 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 744, Total size: 10485633\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0116143FGG14B3OZ7UG|B00NGNNQIG|they are light we...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|they are light we...|    1|[light, weight, w...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 213\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:03 WARN TaskSetManager: Stage 6647 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 426, Total size: 10485385\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0598317G3T7URZAR3W3|B003ZOH63W|By replacing the ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|By replacing the ...|    1|[replacing, origi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 214\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:06 WARN TaskSetManager: Stage 6678 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 428, Total size: 10485523\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0038036HJMMW88H5SCN|B00WA4AM7U|Great fit, like v...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Great fit, like v...|    1|[Great, fit, ,, l...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 215\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:09 WARN TaskSetManager: Stage 6709 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 264, Total size: 10485654\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0473259F6GQNBD88IYN|B00E1ETJPI|Sturdy frame, loo...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Sturdy frame, loo...|    1|[Sturdy, frame, ,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 216\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:12 WARN TaskSetManager: Stage 6740 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 4046, Total size: 10485482\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    4.0|A0020356UF96ZV361ST|B00OQWHTY8|She was looking f...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|She was looking f...|    1|[looking, love, w...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 217\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:15 WARN TaskSetManager: Stage 6771 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 841, Total size: 10485271\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A09678606HNGVR2RCHCS|B0012NV9NQ|Fits perfectly. G...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Fits perfectly. G...|    1|[Fits, perfectly,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 218\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:18 WARN TaskSetManager: Stage 6802 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1172, Total size: 10485677\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0473259F6GQNBD88IYN|B0009IQXJ0|This product is g...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This product is g...|    1|[product, great, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 219\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:20 WARN TaskSetManager: Stage 6833 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 441, Total size: 10485728\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A07023963N70A0104KFS|B00J9XET6K|I really enjoyed ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I really enjoyed ...|    1|[really, enjoyed,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 220\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:22 WARN TaskSetManager: Stage 6864 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1126, Total size: 10484944\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0242421UVUJ5VDYGSLB|B00KO6PCFI|They fit my 1988 ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|They fit my 1988 ...|    1|[fit, 1988, ELect...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 221\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:24 WARN TaskSetManager: Stage 6895 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3738, Total size: 10485501\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0312972X0AKL1EYXWTQ|B00I0CEJC0|Learning resource...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Learning resource...|    1|[Learning, resour...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 222\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:30 WARN TaskSetManager: Stage 6926 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1165, Total size: 10485251\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0196552RI15HI7JB9PW|B00SY8519U|Used to replace t...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Used to replace t...|    1|[Used, replace, s...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 223\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:33 WARN TaskSetManager: Stage 6957 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 357, Total size: 10485598\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+-----------+---------+\n",
      "|overall|          reviewerID|      asin| reviewText|sentiment|\n",
      "+-------+--------------------+----------+-----------+---------+\n",
      "|    5.0|A0423240DMI009PHXTTU|B00M1UWJ5G|works great|        1|\n",
      "+-------+--------------------+----------+-----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+-----------+-----+--------------+\n",
      "| reviewText|label|         token|\n",
      "+-----------+-----+--------------+\n",
      "|works great|    1|[works, great]|\n",
      "+-----------+-----+--------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 224\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:35 WARN TaskSetManager: Stage 6988 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 563, Total size: 10485376\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    3.0|A0936776E22F7GGA97K9|B018DX9EFM|Work decently wel...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Work decently wel...|    0|[Work, decently, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 225\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:37 WARN TaskSetManager: Stage 7019 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 445, Total size: 10485318\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0323662LGDA74F87HNI|B0188TFUO0|Lovely Rhinestone...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Lovely Rhinestone...|    1|[Lovely, Rhinesto...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 226\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:40 WARN TaskSetManager: Stage 7050 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 3299, Total size: 10485126\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|overall|          reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|    4.0|A07908187HMQEVS1DW91|B000R4USAQ|    thanks|        1|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+--------+\n",
      "|reviewText|label|   token|\n",
      "+----------+-----+--------+\n",
      "|    thanks|    1|[thanks]|\n",
      "+----------+-----+--------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 227\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:42 WARN TaskSetManager: Stage 7081 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 347, Total size: 10485587\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    2.0|A1008TVH0VKIA2|B0092QGZVG|I filled one of t...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I filled one of t...|    0|[filled, one, bru...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 228\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:44 WARN TaskSetManager: Stage 7112 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1043, Total size: 10485226\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A100RH4M1W1DF0|B00BUFYFKK|Listen, you just ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Listen, you just ...|    1|[Listen, ,, use, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 229\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:46 WARN TaskSetManager: Stage 7143 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 499, Total size: 10485665\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A10030KC6GYK89|B0094UAO6W|I really do like ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I really do like ...|    1|[really, like, pr...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 230\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:49 WARN TaskSetManager: Stage 7174 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 308, Total size: 10485526\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0352185LEEL6G01JJXG|B008GWOGXG|What's not to lov...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|What's not to lov...|    1|[love, hit, hunky...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 231\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:51 WARN TaskSetManager: Stage 7205 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 4204, Total size: 10483863\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0492785IJQFUQ4Z2SHK|B0074A3WXG|Really liked the ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Really liked the ...|    1|[Really, liked, p...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 232\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:55 WARN TaskSetManager: Stage 7236 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 382, Total size: 10485687\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A100I4UAHGQCF6|B0001DSIVY|The only draw bac...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|The only draw bac...|    1|[draw, back, prod...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 233\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:24:58 WARN TaskSetManager: Stage 7267 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 275, Total size: 10485585\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A00577669P2XCLU956L8|B001NP1RPI|my grandson loves...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|my grandson loves...|    1|[grandson, loves,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 234\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:00 WARN TaskSetManager: Stage 7298 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2946, Total size: 10484616\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0103047AS0C8QKUI0X2|B00BLFTG44|As described = wo...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|As described = wo...|    1|[described, =, wo...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 235\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:05 WARN TaskSetManager: Stage 7329 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1425, Total size: 10484646\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0099735VDZ3HDCAAYKL|B00GN90JB2|This book picks u...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This book picks u...|    1|[book, picks, boo...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 236\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:07 WARN TaskSetManager: Stage 7360 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 408, Total size: 10485533\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    4.0|A0020356UF96ZV361ST|B00ZM8VHAW|She wanted reveng...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|She wanted reveng...|    1|[wanted, revenge,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 237\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:10 WARN TaskSetManager: Stage 7391 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 437, Total size: 10485645\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    4.0|A0020356UF96ZV361ST|B01BWQ16BM|What kind of man ...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|What kind of man ...|    1|[kind, man, drugs...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 238\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:14 WARN TaskSetManager: Stage 7422 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 321, Total size: 10485619\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    2.0|A0020356UF96ZV361ST|B015X7KEDM|This book is not ...|        0|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This book is not ...|    0|[book, ,, assassi...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 239\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:17 WARN TaskSetManager: Stage 7453 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1604, Total size: 10484388\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    2.0|A1003Y4S4RZXD1|B000CDAEVK|Okay, does not wo...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Okay, does not wo...|    0|[Okay, ,, work, n...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 240\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:19 WARN TaskSetManager: Stage 7484 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 516, Total size: 10485316\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0102335OJZYGD6JG8YQ|B00UNAD2KM|I bought this in ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I bought this in ...|    1|[bought, case, ba...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 241\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:24 WARN TaskSetManager: Stage 7515 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 5057, Total size: 10484481\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0256017B9Z8H6QJ5DKZ|B000EBMW9W|They were ok for ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|They were ok for ...|    1|[ok, money, ., do...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 242\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:28 WARN TaskSetManager: Stage 7546 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1381, Total size: 10484764\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1027IMO7ZH95J|B017R708QO|Pumps extremely w...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Pumps extremely w...|    1|[Pumps, extremely...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 243\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:32 WARN TaskSetManager: Stage 7577 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 4491, Total size: 10483079\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1018R3XDDA0KP|B000FKO5CO|Some great song f...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Some great song f...|    1|[great, song, 60'...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 244\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:35 WARN TaskSetManager: Stage 7608 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 967, Total size: 10485744\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    2.0|A1008R8NVX7CJL|B000WJ0IGU|These keep breaki...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|These keep breaki...|    0|[keep, breaking, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 245\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:38 WARN TaskSetManager: Stage 7639 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 625, Total size: 10485329\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100UD67AHFODS|B0056IMXGA|This coffee is ph...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This coffee is ph...|    1|[coffee, phenomen...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 246\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:41 WARN TaskSetManager: Stage 7670 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 963, Total size: 10484853\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|overall|          reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|    5.0|A0986263H7SX62P1SRDD|B00J2N3SLE|      nice|        1|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+------+\n",
      "|reviewText|label| token|\n",
      "+----------+-----+------+\n",
      "|      nice|    1|[nice]|\n",
      "+----------+-----+------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 247\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:44 WARN TaskSetManager: Stage 7701 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 400, Total size: 10485613\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A10044ECXDUVKS|B001DZE5FW|For tuning pegs a...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|For tuning pegs a...|    1|[tuning, pegs, po...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 248\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:48 WARN TaskSetManager: Stage 7732 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 717, Total size: 10485491\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0899941RZRHG466GT32|B000795XMY|I love this stand...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I love this stand...|    1|[love, stand, kit...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 249\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:52 WARN TaskSetManager: Stage 7763 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 315, Total size: 10485467\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A00463782V7TKAP9EMNL|B01F97TMT8|I want to vacatio...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I want to vacatio...|    1|[want, vacation, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 250\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:54 WARN TaskSetManager: Stage 7794 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 4919, Total size: 10482596\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100UD67AHFODS|0975277324|There aren't enou...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|There aren't enou...|    1|[enough, adjectiv...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 251\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:57 WARN TaskSetManager: Stage 7825 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 304, Total size: 10485660\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0598317G3T7URZAR3W3|B000WEOSNY|These fit my 2011...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|These fit my 2011...|    1|[fit, 2011, Ford,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 252\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:25:59 WARN TaskSetManager: Stage 7856 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 349, Total size: 10485526\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+------------------+---------+\n",
      "|overall|          reviewerID|      asin|        reviewText|sentiment|\n",
      "+-------+--------------------+----------+------------------+---------+\n",
      "|    5.0|A06537817FOGTW3Z6J82|B00TV3ZXIG|So cool love this!|        1|\n",
      "+-------+--------------------+----------+------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+------------------+-----+---------------+\n",
      "|        reviewText|label|          token|\n",
      "+------------------+-----+---------------+\n",
      "|So cool love this!|    1|[cool, love, !]|\n",
      "+------------------+-----+---------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 253\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:04 WARN TaskSetManager: Stage 7887 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1075, Total size: 10485596\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A10063PJ5C9WQQ|B0013V58HU|What can I say.  ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|What can I say.  ...|    1|[say, ., easy, in...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 254\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:08 WARN TaskSetManager: Stage 7918 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1188, Total size: 10484825\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0084095I44XW7DFH0TP|B007EA5ZRW|Cute toy, my son ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Cute toy, my son ...|    1|[Cute, toy, ,, so...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 255\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:12 WARN TaskSetManager: Stage 7949 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2710, Total size: 10483261\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0777943FXTJ5LBO18YB|B00RZ62A1O|nice sturdt keeps...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|nice sturdt keeps...|    1|[nice, sturdt, ke...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 256\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:15 WARN TaskSetManager: Stage 7980 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 813, Total size: 10485626\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0385843DE41TCVXH2I1|B001653Z1O|It fits my palm p...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|It fits my palm p...|    1|[fits, palm, pilo...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 257\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:18 WARN TaskSetManager: Stage 8011 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 730, Total size: 10485387\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A100BOT6XWHS5P|B004UUUTGG|These darts work ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|These darts work ...|    1|[darts, work, gre...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 258\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:21 WARN TaskSetManager: Stage 8042 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 854, Total size: 10485568\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0705194P7V8CSORUCST|B00B7CS3UY|Works great, no p...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Works great, no p...|    1|[Works, great, ,,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 259\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:24 WARN TaskSetManager: Stage 8073 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1208, Total size: 10484703\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1002TJUF3NHFY|B0002H3ZLM|I purchased my fi...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I purchased my fi...|    1|[purchased, first...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 260\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:27 WARN TaskSetManager: Stage 8104 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 407, Total size: 10485403\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A101P5UBAWDB62|B001MUHXQ6|One of the best. ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|One of the best. ...|    1|[One, best, ., To...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 261\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:30 WARN TaskSetManager: Stage 8135 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 793, Total size: 10484987\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    5.0|A0020356UF96ZV361ST|B00YM372ZW|It really is a  s...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|It really is a  s...|    1|[really, small, w...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 262\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:33 WARN TaskSetManager: Stage 8166 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 952, Total size: 10485654\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100WHX0JSGXDB|B000U0OUP6|I buy 12 each mon...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I buy 12 each mon...|    1|[buy, 12, month, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 263\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:36 WARN TaskSetManager: Stage 8197 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 543, Total size: 10485530\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100UD67AHFODS|B005DDC5UM|This gum is aweso...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This gum is aweso...|    1|[gum, awesome, .,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 264\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:38 WARN TaskSetManager: Stage 8228 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 390, Total size: 10485460\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A100Z08BO3LTKQ|B001KWGZ38|Too expensive to ...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Too expensive to ...|    1|[expensive, conti...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 265\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:42 WARN TaskSetManager: Stage 8259 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 405, Total size: 10485483\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0490453AYGB1BAAOG64|B00NQN2NQ2|Arrived in excell...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Arrived in excell...|    1|[Arrived, excelle...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 266\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:45 WARN TaskSetManager: Stage 8290 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 598, Total size: 10485568\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|overall|         reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "|    5.0|A0020356UF96ZV361ST|B018GJ95OS|This girl had it ...|        1|\n",
      "+-------+-------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This girl had it ...|    1|[girl, rough, gro...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 267\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:48 WARN TaskSetManager: Stage 8321 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 492, Total size: 10485703\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0103047AS0C8QKUI0X2|B00HZHB0NC|Very interesting ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Very interesting ...|    1|[interesting, toy...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 268\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:51 WARN TaskSetManager: Stage 8352 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1849, Total size: 10483995\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|overall|          reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|    4.0|A05259688OLY40BX186V|B00HWIOK8Q|     Great|        1|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+-------+\n",
      "|reviewText|label|  token|\n",
      "+----------+-----+-------+\n",
      "|     Great|    1|[Great]|\n",
      "+----------+-----+-------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 269\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:54 WARN TaskSetManager: Stage 8383 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1211, Total size: 10485571\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0293100R08JGAQIZ791|B003L4895A|It was a little b...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|It was a little b...|    1|[little, big, cag...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 270\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:26:57 WARN TaskSetManager: Stage 8414 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1398, Total size: 10485034\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0394278SYNCVB733N3F|B015M82SHC|Slices of life is...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Slices of life is...|    1|[Slices, life, co...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 271\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:00 WARN TaskSetManager: Stage 8445 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 308, Total size: 10485663\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0096681Y127OL1H8W3U|B00CHRZ15S|great for my old ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|great for my old ...|    1|[great, old, engl...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 272\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:02 WARN TaskSetManager: Stage 8476 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 581, Total size: 10485466\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+----------+---------+\n",
      "|overall|    reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------+----------+----------+---------+\n",
      "|    5.0|A100GL8WF4V2TZ|B00DH9ABLO| Very good|        1|\n",
      "+-------+--------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+------+\n",
      "|reviewText|label| token|\n",
      "+----------+-----+------+\n",
      "| Very good|    1|[good]|\n",
      "+----------+-----+------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 273\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:06 WARN TaskSetManager: Stage 8507 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 260, Total size: 10485544\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A007917716EGEEP4D8LB|B00Y485F2W|Does its job, was...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Does its job, was...|    1|[job, ,, looking,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 274\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:09 WARN TaskSetManager: Stage 8538 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 421, Total size: 10485575\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100ELBI8BSXR1|B0002ARUV0|MOST DOGS LOVE TH...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|MOST DOGS LOVE TH...|    1|[DOGS, LOVE, OWNE...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 275\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:12 WARN TaskSetManager: Stage 8569 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2296, Total size: 10484638\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    2.0|A1004AX2J2HXGL|B00YZ5D5CQ|Not a bad version...|        0|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Not a bad version...|    0|[bad, version, OG...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 276\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:15 WARN TaskSetManager: Stage 8600 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 444, Total size: 10485356\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0099735VDZ3HDCAAYKL|B00XSAPNME|Sexy oh my. This ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Sexy oh my. This ...|    1|[Sexy, oh, ., boo...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 277\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:18 WARN TaskSetManager: Stage 8631 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1621, Total size: 10484669\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0980592Q6W60Q720SET|B00F1X368O|All 3 books was e...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|All 3 books was e...|    1|[3, books, excell...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 278\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:21 WARN TaskSetManager: Stage 8662 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 538, Total size: 10485276\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    1.0|A0702042KBDIV9DA2V1D|B00EC4WJNQ|I just received t...|        0|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I just received t...|    0|[received, item, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 279\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:24 WARN TaskSetManager: Stage 8693 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 843, Total size: 10485645\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0846724PR6DLXCOTZ18|B000W7GLB8|thank you very mu...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|thank you very mu...|    1|[thank, much, pro...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 280\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:26 WARN TaskSetManager: Stage 8724 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1730, Total size: 10485555\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0096681Y127OL1H8W3U|B006RNQ7YW|best i have every...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+-----------------+\n",
      "|          reviewText|label|            token|\n",
      "+--------------------+-----+-----------------+\n",
      "|best i have every...|    1|[best, everyused]|\n",
      "+--------------------+-----+-----------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 281\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:30 WARN TaskSetManager: Stage 8755 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 272, Total size: 10485513\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100DKGJDUFS2I|B004BP8HPK|This is my second...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|This is my second...|    1|[second, time, or...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 282\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:32 WARN TaskSetManager: Stage 8786 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 2961, Total size: 10485536\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1017UZIPW58F4|B00DV6X57K|Work great - they...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Work great - they...|    1|[Work, great, -, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 283\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:37 WARN TaskSetManager: Stage 8817 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 333, Total size: 10485540\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    4.0|A0878543G7OT1ZKZH5ZY|B019O06FQO|works good and ea...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|works good and ea...|    1|[works, good, eas...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 284\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:41 WARN TaskSetManager: Stage 8848 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 323, Total size: 10485569\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0084095I44XW7DFH0TP|B00FDJY6N0|Other commenters ...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Other commenters ...|    1|[commenters, comp...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 285\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:44 WARN TaskSetManager: Stage 8879 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 519, Total size: 10485275\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "|overall|          reviewerID|      asin|  reviewText|sentiment|\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "|    5.0|A02635363YZWI9MI13CD|B001S1IN72|good product|        1|\n",
      "+-------+--------------------+----------+------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+------------+-----+---------------+\n",
      "|  reviewText|label|          token|\n",
      "+------------+-----+---------------+\n",
      "|good product|    1|[good, product]|\n",
      "+------------+-----+---------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 286\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:49 WARN TaskSetManager: Stage 8910 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 509, Total size: 10485556\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A100W05RDRCLF8|B01CRNF0FM|My 4yr loves this...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|My 4yr loves this...|    1|[4yr, loves, !!, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 287\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:52 WARN TaskSetManager: Stage 8941 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1854, Total size: 10484125\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A101FALL0U1DV5|B0021F89W8|great product che...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|great product che...|    1|[great, product, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 288\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:54 WARN TaskSetManager: Stage 8972 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 1358, Total size: 10485365\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A10063PJ5C9WQQ|B007005364|In the past I hav...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|In the past I hav...|    1|[past, used, X10,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 289\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:27:58 WARN TaskSetManager: Stage 9003 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 484, Total size: 10485472\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    5.0|A1000EWBXBHK0P|B00199LO1U|Perfect fit and e...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|Perfect fit and e...|    1|[Perfect, fit, ea...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 290\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:28:01 WARN TaskSetManager: Stage 9034 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 311, Total size: 10485727\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|overall|          reviewerID|      asin|reviewText|sentiment|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "|    5.0|A0034986DWR7WEDQN0GV|B001VJZO2S| excellent|        1|\n",
      "+-------+--------------------+----------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+----------+-----+-----------+\n",
      "|reviewText|label|      token|\n",
      "+----------+-----+-----------+\n",
      "| excellent|    1|[excellent]|\n",
      "+----------+-----+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 291\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:28:03 WARN TaskSetManager: Stage 9065 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 364, Total size: 10485460\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0629255VPARUWJZM5XI|B004713BR2|They fit and were...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|They fit and were...|    1|[fit, delivered, ...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 292\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:28:06 WARN TaskSetManager: Stage 9096 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 413, Total size: 10485557\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|overall|          reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "|    5.0|A0980592Q6W60Q720SET|B01AXD0SQO|I wasn't sure abo...|        1|\n",
      "+-------+--------------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n",
      "+--------------------+-----+--------------------+\n",
      "|          reviewText|label|               token|\n",
      "+--------------------+-----+--------------------+\n",
      "|I wasn't sure abo...|    1|[sure, book, firs...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Run 293\n",
      "Model type: org.apache.spark.ml.PipelineModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/25 15:28:09 WARN TaskSetManager: Stage 9127 contains a task of very large size (3212 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for current chunk\n",
      "Current line size: 522, Total size: 10485675\n",
      "Processing chunk\n",
      "Show the first row of the preprocessed chunk:\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|overall|    reviewerID|      asin|          reviewText|sentiment|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "|    4.0|A101NPAJJ3114Q|B00061UPP8|Very good. Took a...|        1|\n",
      "+-------+--------------+----------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n",
      "Show the first row of the transformed chunk:\n"
     ]
    }
   ],
   "source": [
    "# Define the maximum file size in bytes (10MB)\n",
    "max_file_size = 10 * 1024 * 1024\n",
    "json_training_file_path = \"combined_train_data_chunked_10mb_latest.json\"\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pyspark.ml.tuning import CrossValidatorModel\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    " \n",
    "\n",
    "\n",
    "def transform_chunk(df):\n",
    "    nlpPipeline = get_nlp_pipeline()\n",
    "    tokenized_df = nlpPipeline.fit(df).transform(df)\n",
    "    #tokenized_df.select(\"cleanTokens.result\").show(1)\n",
    "    df6_train = tokenized_df.where(F.size(F.col(\"cleanTokens\")) > 0)\n",
    "    df_train_for_model = df6_train.select(\"reviewText\",\"sentiment\", \"cleanTokens.result\").withColumnRenamed(\"sentiment\", \"label\").withColumnRenamed(\"result\", \"token\")\n",
    "    return df_train_for_model\n",
    "\n",
    "def run_cross_validation(df_train, pipeline, stem_pipeline, run):\n",
    "    stages_steps = []\n",
    "    train_stem = stem_pipeline.transform(df_train)\\\n",
    "                          .where(F.size(F.col(\"stemmed\")) >= 1)\n",
    "    print(\"Run %d\" % run)\n",
    "    if os.path.exists('crossval_pipeline_model'):\n",
    "        model_type = identify_model_type('crossval_pipeline_model')\n",
    "        print(\"Model type: %s\" % model_type)\n",
    "        if \"CrossValidatorModel\" in model_type:\n",
    "            loaded_model = CrossValidatorModel.load('crossval_pipeline_model')\n",
    "            stages_steps = loaded_model.bestModel.stages \n",
    "        elif \"PipelineModel\" in model_type:\n",
    "            loaded_model = PipelineModel.load('crossval_pipeline_model')\n",
    "            stages_steps = loaded_model.stages\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported or unknown model type\")\n",
    "        updated_model = Pipeline(stages = stages_steps).fit(train_stem)\n",
    "        updated_model.write().overwrite().save('crossval_pipeline_model')\n",
    "    else:\n",
    "        print(\"Printing data frame for training\")\n",
    "        train_stem.show(1)\n",
    "        updated_model = pipeline.fit(train_stem)\n",
    "        updated_model.write().overwrite().save('crossval_pipeline_model')\n",
    "    run +=1\n",
    "    print('Model saved for current chunk')\n",
    "    return run\n",
    "\n",
    "run = 0\n",
    "with open(json_training_file_path, 'r') as file:\n",
    "    total_size = 0\n",
    "    for line in file:\n",
    "        line_size = sys.getsizeof(line)\n",
    "        # print(\"Current line size: %d, Total size: %d\" % (line_size, total_size))\n",
    "        if total_size + line_size >= max_file_size:\n",
    "            print(\"Current line size: %d, Total size: %d\" % (line_size, total_size))\n",
    "            df  = pre_process(line)\n",
    "            print(\"Show the first row of the preprocessed chunk:\")\n",
    "            df.show(1)\n",
    "            df_train = transform_chunk(df)\n",
    "            print(\"Show the first row of the transformed chunk:\")\n",
    "            df_train.show(1)\n",
    "            crossval, stemmer = get_crossval_evaluator()\n",
    "            run = run_cross_validation(df_train, crossval, stemmer, run)\n",
    "            del df\n",
    "            del df_train\n",
    "            json_objects = []\n",
    "            total_size = 0\n",
    "        json_objects.append(json.loads(line))\n",
    "        total_size += line_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
