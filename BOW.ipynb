{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ff5f42-3947-49a5-8389-a1d6fb046940",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb23064-87ae-4ca9-92a4-0d111580b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, BooleanType, IntegerType\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b27a9b65-f5f4-4ef3-9994-33668ef59215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ReadJSON\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78fc04e3-b382-40d2-9734-4152327cc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"asin\", StringType(), True),\n",
    "        StructField(\"reviewerID\", StringType(), True),\n",
    "        StructField(\"summary\", StringType(), True),\n",
    "        StructField(\"overall\", StringType(), True),\n",
    "        StructField(\"reviewText\", StringType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# read a JSON file into a DataFrame\n",
    "df_raw = spark.read.schema(schema).json(r\"C:\\Users\\Emma\\Downloads\\school\\Big_Data\\project\\finaldata\\combined_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ab7c7446-c092-4f86-a0ca-d593e25812a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112869"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 1% of data\n",
    "df = df_raw.sample(withReplacement=False, fraction=0.01)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "72ac2981-f8c3-47d7-a357-b57eae81b0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Emma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# pre-process functions\n",
    "import pyspark.sql.functions as F\n",
    "labelUDF = F.udf(lambda x: 1 if float(x) >= 4.0 else 0, IntegerType())\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "def remove_reg_stop(text: str) -> str:\n",
    "    text = re.sub(r'[^\\w]', ' ', text).lower()\n",
    "    lst = text.split(' ')\n",
    "    lst = list(filter(None, lst))\n",
    "    lst = [word for word in lst if word not in STOPWORDS]\n",
    "    str = ' '.join(lst)\n",
    "    return str\n",
    "cleanTextUDF = F.udf(remove_reg_stop, StringType())\n",
    "\n",
    "def preProc (df):\n",
    "    df_labeled_cleaned = df.dropDuplicates([\"reviewerID\", \"asin\"])\n",
    "    df_labeled_cleaned = df_labeled_cleaned.na.drop()\n",
    "    df_labeled_cleaned = df_labeled_cleaned.withColumn(\"label\", labelUDF(df_labeled_cleaned[\"overall\"]))\n",
    "    df_labeled_cleaned = df_labeled_cleaned.select(\"reviewText\", \"label\")\n",
    "    df_labeled_cleaned = df_labeled_cleaned.withColumn(\"cleanText\", cleanTextUDF(df_labeled_cleaned[\"reviewText\"]))\n",
    "    return df_labeled_cleaned.select(\"cleanText\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ffc85cb6-2358-4c0a-8c8c-268db1fdfca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 15.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "112744"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_labeled_cleaned = preProc(df)\n",
    "df_labeled_cleaned.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6f20bf-6c46-4273-a06c-200083b8ee1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|95146|\n",
      "|    0|17593|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_labeled_cleaned.groupby(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7759b219-9426-453b-a21f-aaa23f7911b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'areaUnderROC'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "\n",
    "# get the name of the metric used\n",
    "evaluator.getMetricName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a689de-c62f-4374-a79e-2db95978f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokens from reviews\n",
    "tk = Tokenizer(inputCol= \"cleanText\", outputCol = \"tokens\")\n",
    "\n",
    "# create term frequencies for each of the tokens\n",
    "tf1 = HashingTF(inputCol=\"tokens\", outputCol=\"rawFeatures\", numFeatures=1e5)\n",
    "\n",
    "# create tf-idf for each of the tokens\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=2.0)\n",
    "\n",
    "# create basic logistic regression model\n",
    "lr = LogisticRegression(maxIter=20)\n",
    "\n",
    "# create entire pipeline\n",
    "basic_pipline = Pipeline(stages=[tk, tf1, idf, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c69cb2f0-7a24-49b9-aa86-fcc546ed03c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cleanText: string, label: int]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled_cleaned.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09c447fe-5b0e-47b1-a317-60daacf04823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 344 ms\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model1 = basic_pipline.fit(df_labeled_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b5964e3-c588-4c70-b289-75169c430d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"bow_model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bfacc28-72dd-42fe-b8c5-e3509e91762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on testing data\n",
    "\n",
    "df2_raw = spark.read.schema(schema).json(r\"C:\\Users\\Emma\\Downloads\\school\\Big_Data\\project\\finaldata\\combined_test.json\")\n",
    "df2 = df2_raw.sample(withReplacement=False, fraction=0.01)\n",
    "df2_labeled_cleaned = preProc(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "594e77a4-95b9-43d6-ad47-31cd19f4fdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28435"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_labeled_cleaned.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94da99dc-d293-4279-aae3-11796f96b538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.768647368109351\n"
     ]
    }
   ],
   "source": [
    "predictions = model1.transform(df2_labeled_cleaned)\n",
    "score = evaluator.evaluate(predictions)\n",
    "print(\"AUC SCORE: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07ef8eb2-cb06-4cb6-9f23-dcfb2d9152c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|           cleanText|label|              tokens|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                 5 5|    1|              [5, 5]|(100000,[27741],[...|(100000,[27741],[...|[-0.9840254475377...|[0.27209377750342...|       1.0|\n",
      "|great experience ...|    1|[great, experienc...|(100000,[10447,11...|(100000,[10447,11...|[-7.2627705032405...|[7.00671483686858...|       1.0|\n",
      "|brmc right place ...|    1|[brmc, right, pla...|(100000,[712,3021...|(100000,[712,3021...|[-38.652144337936...|[1.63526070291485...|       1.0|\n",
      "|          great yarn|    1|       [great, yarn]|(100000,[6564,607...|(100000,[6564,607...|[-1.0463793950310...|[0.25992096220753...|       1.0|\n",
      "|product works fan...|    1|[product, works, ...|(100000,[10447,27...|(100000,[10447,27...|[-11.673163774503...|[8.51933481204719...|       1.0|\n",
      "|pretty doll earri...|    0|[pretty, doll, ea...|(100000,[6173,105...|(100000,[6173,105...|[-4.4458362223545...|[0.01159136000134...|       1.0|\n",
      "|size right like w...|    0|[size, right, lik...|(100000,[2543,821...|(100000,[2543,821...|[55.1466451730936...|           [1.0,0.0]|       0.0|\n",
      "|nice small easy t...|    1|[nice, small, eas...|(100000,[3370,101...|(100000,[3370,101...|[2.04740780248308...|[0.88568542942402...|       0.0|\n",
      "|                good|    1|              [good]|(100000,[86168],[...|(100000,[86168],[...|[-1.1492552365066...|[0.24062514343523...|       1.0|\n",
      "|works perfect 82 ...|    1|[works, perfect, ...|(100000,[15484,18...|(100000,[15484,18...|[-19.952571668551...|[2.16126601107123...|       1.0|\n",
      "|fit great worked ...|    1|[fit, great, work...|(100000,[10506,48...|(100000,[10506,48...|[-5.8599342009926...|[0.00284332375550...|       1.0|\n",
      "|decent product gr...|    1|[decent, product,...|(100000,[10447,41...|(100000,[10447,41...|[-4.0244571279684...|[0.01755928505432...|       1.0|\n",
      "|loved kept intere...|    1|[loved, kept, int...|(100000,[11226,27...|(100000,[11226,27...|[-0.0920727043020...|[0.47699807130873...|       1.0|\n",
      "|arrived time good...|    1|[arrived, time, g...|(100000,[2918,101...|(100000,[2918,101...|[2.50315110518575...|[0.92436242913340...|       0.0|\n",
      "|good book also fu...|    1|[good, book, also...|(100000,[712,1039...|(100000,[712,1039...|[-6.0964631062979...|[0.00224575976071...|       1.0|\n",
      "|decent pad poor l...|    0|[decent, pad, poo...|(100000,[668,1100...|(100000,[668,1100...|[8.87479870472520...|[0.99986014977993...|       0.0|\n",
      "|daughter really l...|    1|[daughter, really...|(100000,[10393,50...|(100000,[10393,50...|[3.69428667206040...|[0.97573809243614...|       0.0|\n",
      "|seem like lot nei...|    1|[seem, like, lot,...|(100000,[14943,23...|(100000,[14943,23...|[3.35649680299828...|[0.96631693894910...|       0.0|\n",
      "|cats 14 2 years h...|    1|[cats, 14, 2, yea...|(100000,[1181,985...|(100000,[1181,985...|[1.65533995088908...|[0.83961145463698...|       0.0|\n",
      "|seems job need tr...|    1|[seems, job, need...|(100000,[2543,165...|(100000,[2543,165...|[-16.500024524451...|[6.82543551834307...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b033a47-9969-40c6-9121-1872a7f23895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with self defined input\n",
    "\n",
    "def createInput(lst):\n",
    "    # returns a df to train from giving list of strings\n",
    "    df = spark.createDataFrame([(review,) for review in lst], [\"reviewText\"])\n",
    "    df = df.withColumn(\"cleanText\", cleanTextUDF(df[\"reviewText\"]))\n",
    "    return df\n",
    "\n",
    "tmp_reviews = [\n",
    "    \"This is a great product.\",\n",
    "    \"I love this item!\",\n",
    "    \"Not satisfied with the quality.\", \n",
    "    \"k\",\n",
    "    \"nice item however something wrong\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2117fc3a-9367-4c9b-8dc4-a3e47a9e82bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|           cleanText|prediction|\n",
      "+--------------------+----------+\n",
      "|       great product|       1.0|\n",
      "|           love item|       1.0|\n",
      "|   satisfied quality|       1.0|\n",
      "|                   k|       1.0|\n",
      "|nice item however...|       1.0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test2 = createInput(tmp_reviews)\n",
    "pred_test = model1.transform(df_test2)\n",
    "pred_test.select(\"cleanText\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b735d7-6cf0-4712-875e-23d75603bf2b",
   "metadata": {},
   "source": [
    "## using equal label training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b332dff9-cecb-42cd-abb1-c0e3b4e2e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the numbers of data with label 0 and sample the same amount from data with label 1\n",
    "df_labeled_0 = df_labeled_cleaned.filter(df_labeled_cleaned[\"label\"]==0)\n",
    "df_labeled_1 = df_labeled_cleaned.filter(df_labeled_cleaned[\"label\"]==1)\n",
    "FRAC_1 = df_labeled_0.count()/df_labeled_1.count()\n",
    "df_labeled_1 = df_labeled_1.sample(withReplacement=False, fraction=FRAC_1, seed=42)\n",
    "\n",
    "# combine\n",
    "df_equal_label = df_labeled_0.union(df_labeled_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "978d5de9-c541-4993-8a39-12f776e2db44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35538"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_equal_label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6e324a0-9522-4ec8-a07b-1f4d47d78c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|17593|\n",
      "|    1|17945|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_equal_label.groupby(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d999df4f-fe56-4d1a-ade2-e76bbc3b8df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create entire pipeline\n",
    "pipline2 = Pipeline(stages=[tk, tf1, idf, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96e607cf-60e1-452c-a035-b4a837aee4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 406 ms\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model2 = pipline2.fit(df_equal_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8182fbf1-d790-43bf-be22-aa44a859f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"bow_model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c038d0d-090f-46b2-ab02-6184944b4980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORE: 0.7687397631638292\n"
     ]
    }
   ],
   "source": [
    "predictions = model2.transform(df2_labeled_cleaned)\n",
    "score = evaluator.evaluate(predictions)\n",
    "print(\"AUC SCORE: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9db659ea-1ef7-4161-aff6-05e58f280622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|           cleanText|prediction|\n",
      "+--------------------+----------+\n",
      "|       great product|       1.0|\n",
      "|           love item|       1.0|\n",
      "|   satisfied quality|       1.0|\n",
      "|                   k|       0.0|\n",
      "|nice item however...|       0.0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = model2.transform(df_test2)\n",
    "pred_test.select(\"cleanText\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8657e969-6a21-4040-84b1-f05bf7473c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear everything\n",
    "import gc\n",
    "\n",
    "spark.stop()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c248c-8236-4b40-90bf-2078d8bfb54a",
   "metadata": {},
   "source": [
    "## loading data 10mb at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19951803-b353-4667-bcbc-10b73a7ff53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"ReadJSON_chunks\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e226243-7236-446d-bc35-8864e856aded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = r\"C:\\Users\\Emma\\Downloads\\school\\Big_Data\\project\\finaldata\\combined_train.json\"\n",
    "\n",
    "# Define chunk size in lines\n",
    "chunk_size_line = 20000\n",
    "\n",
    "# define schema\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"asin\", StringType(), True),\n",
    "        StructField(\"reviewerID\", StringType(), True),\n",
    "        StructField(\"summary\", StringType(), True),\n",
    "        StructField(\"overall\", StringType(), True),\n",
    "        StructField(\"reviewText\", StringType(), True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72391ba9-4acb-4294-8872-a95e25d9ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json with file open\n",
    "\n",
    "f = open(file_path, \"r\")\n",
    "f_content = ''\n",
    "for i in range(chunk_size_line):\n",
    "    f_content+=f.readline()\n",
    "\n",
    "# write to a tmp json file\n",
    "with open(\"tmp.json\", \"w\") as outfile:\n",
    "    outfile.write(f_content)\n",
    "\n",
    "# free memory\n",
    "del f_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d13ad12f-ee89-4411-9f73-5cafd2a90ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = spark.read.schema(schema).json(r\"C:\\Users\\Emma\\Downloads\\school\\Big_Data\\project\\big-data-final-project\\tmp.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d29c33f6-227b-49a3-b865-e1aae9b84e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+-------+--------------------+\n",
      "|      asin|    reviewerID|             summary|overall|          reviewText|\n",
      "+----------+--------------+--------------------+-------+--------------------+\n",
      "|0486427706|A1274GG1EB2JLJ|The pictures are ...|    5.0|The pictures are ...|\n",
      "|0486427706|A30X5EGBYAZQQK|       So beautiful!|    5.0|I absolutely love...|\n",
      "|0486427706|A3U6UNXLAUY6ZV|          Five Stars|    5.0|          I love it!|\n",
      "|0486427706|A1SAJF5SNM6WJS|          Five Stars|    5.0|MY HUSBAND LOVED ...|\n",
      "|0486427706| AHJWO3SI0S0OR|          Four Stars|    4.0|                cool|\n",
      "|0486427706| ALLSNTNR6N6UL|nice pictures, gr...|    5.0|Exactly as descri...|\n",
      "|0486448789|A3O6CP5TT54LJE|     save your money|    1.0|total waste of mo...|\n",
      "|0486448789|A216BPGO0ZBR5N|age 5 loved the b...|    5.0|Nephew, age 5 lov...|\n",
      "|0486448789|A3OJCR7TKQIPQM|          Very Cute!|    5.0|          Very Cute!|\n",
      "|0486448789|A2DSZOLDOG70GC|This is pretty mu...|    3.0|This is pretty mu...|\n",
      "|0486448789|A1ZXYT6S1SZ087|          Five Stars|    5.0|AGE APPROPIATE. G...|\n",
      "|0486448789|A3K4NTIXV7Z559|                Tiny|    4.0|its a cute little...|\n",
      "|0486448789|A3EAVL6N8Q6MOA|Really small disa...|    2.0|They were ok but ...|\n",
      "|0486448789|A15UXQOOJ0TL8K|          Five Stars|    5.0|        Good product|\n",
      "|0486448789| AI3JLLMYH16NZ|It was cute and h...|    4.0|This was a stocki...|\n",
      "|0486448789|A2KBV1CL6U7CBV|               robot|    5.0|            Fun gift|\n",
      "|0486448789| ARMU5CK7T1RZ9|          Five Stars|    5.0|          great book|\n",
      "|0486448789|A2G7033C3Z61KL|          Five Stars|    5.0|   Grandson loved it|\n",
      "|0486448789|A1NVBHOKOP8N9G|          Five Stars|    5.0|This is a small book|\n",
      "|0486448789|A1NH7LYE1XIICF|a wonderful littl...|    5.0|a wonderful littl...|\n",
      "+----------+--------------+--------------------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7db2a5f4-5bc6-483d-834c-562ca7fb3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()\n",
    "del df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd894bac-058e-4402-8832-c8b96409685f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+-------+--------------------+\n",
      "|      asin|    reviewerID|             summary|overall|          reviewText|\n",
      "+----------+--------------+--------------------+-------+--------------------+\n",
      "|B00004T2WP|A360ADK9Q5VTF3|    It's okay but...|    3.0|my son never had ...|\n",
      "|B00004T2WP|A2W5EPWH46DUCL|                Gift|    5.0|This was a gift t...|\n",
      "|B00004T2WP|A1I10L12MM57S0|Perfect walk/ride...|    5.0|I was looking for...|\n",
      "|B00004T2WP|A2R0MYROYFQIXY|           Love this|    5.0|this is so great,...|\n",
      "|B00004T2WP|A335RCAJ27KI7R|Fun toy once they...|    5.0|This toy is good ...|\n",
      "|B00004T2WP| A9D25J81K1ZSB|Used through 2 ch...|    5.0|I purchased this ...|\n",
      "|B00004T2WP|A2FCS6WYO0HCW7|        not rideable|    1.0|Neither of my chi...|\n",
      "|B00004T2WP|A2ROUV2OWG4TI2|      babies LOVE IT|    5.0|my son was trying...|\n",
      "|B00004T2WP| AXY7LB6MPS5VM|Perfect for learn...|    5.0|This has been rea...|\n",
      "|B00004T2WP|A3M424W9HTCTNL|My baby does not ...|    3.0|I bought a used o...|\n",
      "|B00004T2WP|A12H774IJ9EWZI|Must have for all...|    5.0|I bought this sec...|\n",
      "|B00004T2WP| AJGU56YG8G1DQ| Great for Toddlers!|    5.0|This is fantastic...|\n",
      "|B00004T2WP|A1XI7OHZRNJ4ZR|Not good as a wal...|    1.0|This toy as a rid...|\n",
      "|B00004T2WP|A3HLVR6FQ1CYOF|Playskool Step St...|    5.0|I bought this for...|\n",
      "|B00004T2WP|A2APK9SE89V90I|Great for new wal...|    5.0|I bought this for...|\n",
      "|B00004T2WP| ACR9ES55PCMHO|Hard to use for t...|    2.0|This toy seems to...|\n",
      "|B00004T2WP|A1OGZK7JDXK6EC|        Lot's of Fun|    4.0|We just put this ...|\n",
      "|B00004T2WP| A79U7OPQX5W1M|          Very happy|    5.0|I bought this for...|\n",
      "|B00004T2WP|A2L6LGTCAO02FY|Teaches kids how ...|    5.0|I bought this for...|\n",
      "|B00004T2WP|A2TSFXHN3IMGXG|You get what you ...|    2.0|This toy is cheap...|\n",
      "+----------+--------------+--------------------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_content = ''\n",
    "for i in range(chunk_size_line):\n",
    "    f_content+=f.readline()\n",
    "\n",
    "# write to a tmp json file\n",
    "with open(\"tmp.json\", \"w\") as outfile:\n",
    "    outfile.write(f_content)\n",
    "\n",
    "# free memory\n",
    "del f_content\n",
    "\n",
    "df_raw = spark.read.schema(schema).json(r\"C:\\Users\\Emma\\Downloads\\school\\Big_Data\\project\\big-data-final-project\\tmp.json\")\n",
    "df_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b65f0f29-0698-40fc-b847-e256ff55b515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3312"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear everything\n",
    "import gc\n",
    "\n",
    "spark.stop()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b841df6d-6138-436f-ba4b-9c0ef2ee47d1",
   "metadata": {},
   "source": [
    "## putting everying in loop..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f69f44d-b982-4d93-87fd-802340696a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, BooleanType, IntegerType\n",
    "from pyspark.sql.functions import col, struct\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.pipeline import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbffc19-4fe4-412a-a12c-c23e3bc5053d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Emma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# pre-process functions\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "labelUDF = F.udf(lambda x: 1 if float(x) >= 4.0 else 0, IntegerType())\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "def remove_reg_stop(text: str) -> str:\n",
    "    text = re.sub(r'[^\\w]', ' ', text).lower()\n",
    "    lst = text.split(' ')\n",
    "    lst = list(filter(None, lst))\n",
    "    lst = [word for word in lst if word not in STOPWORDS]\n",
    "    str = ' '.join(lst)\n",
    "    return str\n",
    "cleanTextUDF = F.udf(remove_reg_stop, StringType())\n",
    "\n",
    "def preProc (df):\n",
    "    df_labeled_cleaned = df.dropDuplicates([\"reviewerID\", \"asin\"])\n",
    "    df_labeled_cleaned = df_labeled_cleaned.na.drop()\n",
    "    df_labeled_cleaned = df_labeled_cleaned.withColumn(\"label\", labelUDF(df_labeled_cleaned[\"overall\"]))\n",
    "    df_labeled_cleaned = df_labeled_cleaned.select(\"reviewText\", \"label\")\n",
    "    df_labeled_cleaned = df_labeled_cleaned.withColumn(\"cleanText\", cleanTextUDF(df_labeled_cleaned[\"reviewText\"]))\n",
    "    return df_labeled_cleaned.select(\"cleanText\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27dee5e5-510f-472b-a522-fa5d651e770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"ReadJSON_chunks\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274be368-3f76-4c49-a6aa-3bba6d86808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = r\"C:\\Users\\Emma\\Downloads\\school\\Big_Data\\project\\finaldata\\combined_train.json\"\n",
    "\n",
    "# Define chunk size in lines\n",
    "chunk_size_line = 20000\n",
    "\n",
    "# define schema\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"asin\", StringType(), True),\n",
    "        StructField(\"reviewerID\", StringType(), True),\n",
    "        StructField(\"summary\", StringType(), True),\n",
    "        StructField(\"overall\", StringType(), True),\n",
    "        StructField(\"reviewText\", StringType(), True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a2280f-42c3-4d96-af37-e9c7dd95571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load testing data\n",
    "\n",
    "df_test = spark.read.schema(schema).json(r\"C:\\Users\\Emma\\Downloads\\school\\Big_Data\\project\\finaldata\\combined_test.json\")\n",
    "df_test = preProc(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e598b0-0041-41d8-a182-7f2c141430bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipline\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "tk = Tokenizer(inputCol= \"cleanText\", outputCol = \"tokens\")\n",
    "tf1 = HashingTF(inputCol=\"tokens\", outputCol=\"rawFeatures\", numFeatures=1e5)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=2.0)\n",
    "lr = LogisticRegression(maxIter=20)\n",
    "basic_pipline = Pipeline(stages=[tk, tf1, idf, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76955871-ec21-4733-bd2e-61e7a7c70bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bow_chunk_model_1 AUC SCORE: 0.6861595761437362\n",
      "bow_chunk_model_2 AUC SCORE: 0.6861581332194084\n",
      "bow_chunk_model_3 AUC SCORE: 0.686162518257355\n",
      "bow_chunk_model_4 AUC SCORE: 0.6861598047388178\n",
      "bow_chunk_model_5 AUC SCORE: 0.6861611665852446\n",
      "bow_chunk_model_6 AUC SCORE: 0.6861624778486394\n",
      "bow_chunk_model_7 AUC SCORE: 0.6861547961699533\n",
      "bow_chunk_model_8 AUC SCORE: 0.6861608787377532\n",
      "bow_chunk_model_9 AUC SCORE: 0.6861575371895784\n",
      "bow_chunk_model_10 AUC SCORE: 0.6861555317360544\n",
      "bow_chunk_model_11 AUC SCORE: 0.6861635508892369\n",
      "bow_chunk_model_12 AUC SCORE: 0.6861579915051954\n",
      "bow_chunk_model_13 AUC SCORE: 0.6861607861460787\n",
      "bow_chunk_model_14 AUC SCORE: 0.6861575758615918\n",
      "bow_chunk_model_15 AUC SCORE: 0.6861565341645833\n",
      "bow_chunk_model_16 AUC SCORE: 0.6861540429121991\n",
      "bow_chunk_model_17 AUC SCORE: 0.6861565404578753\n",
      "bow_chunk_model_18 AUC SCORE: 0.6861580958657479\n",
      "bow_chunk_model_19 AUC SCORE: 0.6861556185557579\n",
      "bow_chunk_model_20 AUC SCORE: 0.6861550865482063\n",
      "bow_chunk_model_21 AUC SCORE: 0.6861542180113018\n",
      "bow_chunk_model_22 AUC SCORE: 0.6861631522364485\n",
      "bow_chunk_model_23 AUC SCORE: 0.6861623354308722\n",
      "bow_chunk_model_24 AUC SCORE: 0.6861608046525035\n",
      "bow_chunk_model_25 AUC SCORE: 0.6861546903335148\n",
      "bow_chunk_model_26 AUC SCORE: 0.6861585117836694\n",
      "bow_chunk_model_27 AUC SCORE: 0.6861628233076807\n",
      "bow_chunk_model_28 AUC SCORE: 0.6861591384255017\n",
      "bow_chunk_model_29 AUC SCORE: 0.6861582960507998\n",
      "bow_chunk_model_30 AUC SCORE: 0.6861629587359802\n",
      "bow_chunk_model_31 AUC SCORE: 0.686154547866238\n",
      "bow_chunk_model_32 AUC SCORE: 0.6861612052138448\n",
      "bow_chunk_model_33 AUC SCORE: 0.6861534670324377\n",
      "bow_chunk_model_34 AUC SCORE: 0.6861561823435255\n",
      "bow_chunk_model_35 AUC SCORE: 0.6861608847764882\n",
      "bow_chunk_model_36 AUC SCORE: 0.6861596602766692\n",
      "bow_chunk_model_37 AUC SCORE: 0.6861580003212755\n",
      "bow_chunk_model_38 AUC SCORE: 0.6861602680571983\n",
      "bow_chunk_model_39 AUC SCORE: 0.6861617163107095\n",
      "bow_chunk_model_40 AUC SCORE: 0.6861560044170184\n",
      "bow_chunk_model_41 AUC SCORE: 0.6861646876626045\n",
      "bow_chunk_model_42 AUC SCORE: 0.6861597369690373\n",
      "bow_chunk_model_43 AUC SCORE: 0.6861633509743925\n",
      "bow_chunk_model_44 AUC SCORE: 0.6861596781362771\n",
      "bow_chunk_model_45 AUC SCORE: 0.6861583979637093\n",
      "bow_chunk_model_46 AUC SCORE: 0.686160017010826\n",
      "bow_chunk_model_47 AUC SCORE: 0.6861633932092256\n",
      "bow_chunk_model_48 AUC SCORE: 0.6861658876245261\n",
      "bow_chunk_model_49 AUC SCORE: 0.6861593232626877\n",
      "bow_chunk_model_50 AUC SCORE: 0.68616167447578\n",
      "bow_chunk_model_51 AUC SCORE: 0.6861612751804769\n",
      "bow_chunk_model_52 AUC SCORE: 0.6861575152476638\n",
      "bow_chunk_model_53 AUC SCORE: 0.6861566310191507\n",
      "bow_chunk_model_54 AUC SCORE: 0.6861538361330985\n",
      "bow_chunk_model_55 AUC SCORE: 0.6861542619193384\n",
      "bow_chunk_model_56 AUC SCORE: 0.6861644029880367\n",
      "bow_chunk_model_57 AUC SCORE: 0.6861586857271194\n",
      "bow_chunk_model_58 AUC SCORE: 0.6861574618808953\n",
      "bow_chunk_model_59 AUC SCORE: 0.686152168062474\n",
      "bow_chunk_model_60 AUC SCORE: 0.6861566311668146\n",
      "bow_chunk_model_61 AUC SCORE: 0.6861652054653556\n",
      "bow_chunk_model_62 AUC SCORE: 0.6861592151193222\n",
      "bow_chunk_model_63 AUC SCORE: 0.6861602557686416\n",
      "bow_chunk_model_64 AUC SCORE: 0.6861571593215443\n",
      "bow_chunk_model_65 AUC SCORE: 0.6861573308752565\n",
      "bow_chunk_model_66 AUC SCORE: 0.6861574024923374\n",
      "bow_chunk_model_67 AUC SCORE: 0.6861549617221882\n",
      "bow_chunk_model_68 AUC SCORE: 0.686158194759532\n",
      "bow_chunk_model_69 AUC SCORE: 0.6861548634272909\n",
      "bow_chunk_model_70 AUC SCORE: 0.6861577748077179\n",
      "bow_chunk_model_71 AUC SCORE: 0.6861552908513917\n",
      "bow_chunk_model_72 AUC SCORE: 0.6861567648333121\n",
      "bow_chunk_model_73 AUC SCORE: 0.6861598108814472\n",
      "bow_chunk_model_74 AUC SCORE: 0.6861603802872279\n",
      "bow_chunk_model_75 AUC SCORE: 0.6861529531009066\n",
      "bow_chunk_model_76 AUC SCORE: 0.6861580932339381\n",
      "bow_chunk_model_77 AUC SCORE: 0.6861582661781135\n",
      "bow_chunk_model_78 AUC SCORE: 0.6861573906307961\n",
      "bow_chunk_model_79 AUC SCORE: 0.6861559871930922\n",
      "bow_chunk_model_80 AUC SCORE: 0.6861563994920338\n",
      "bow_chunk_model_81 AUC SCORE: 0.6861626899302178\n",
      "bow_chunk_model_82 AUC SCORE: 0.6861630510560497\n",
      "bow_chunk_model_83 AUC SCORE: 0.686159746967106\n",
      "bow_chunk_model_84 AUC SCORE: 0.6861574398174605\n",
      "bow_chunk_model_85 AUC SCORE: 0.6861616066645594\n",
      "bow_chunk_model_86 AUC SCORE: 0.6861553727836562\n",
      "bow_chunk_model_87 AUC SCORE: 0.6861556633526837\n",
      "bow_chunk_model_88 AUC SCORE: 0.6861590495815898\n",
      "bow_chunk_model_89 AUC SCORE: 0.6861559877818122\n",
      "bow_chunk_model_90 AUC SCORE: 0.6861613754032377\n",
      "bow_chunk_model_91 AUC SCORE: 0.6861587048803613\n",
      "bow_chunk_model_92 AUC SCORE: 0.6861563078899505\n",
      "bow_chunk_model_93 AUC SCORE: 0.6861568891388746\n",
      "bow_chunk_model_94 AUC SCORE: 0.686152804005691\n",
      "bow_chunk_model_95 AUC SCORE: 0.6861646209286056\n",
      "bow_chunk_model_96 AUC SCORE: 0.6861596337029437\n",
      "bow_chunk_model_97 AUC SCORE: 0.686155222417077\n",
      "bow_chunk_model_98 AUC SCORE: 0.6861575421080028\n",
      "bow_chunk_model_99 AUC SCORE: 0.6861531224469197\n",
      "bow_chunk_model_100 AUC SCORE: 0.686158687525232\n",
      "bow_chunk_model_101 AUC SCORE: 0.6861566408724603\n",
      "bow_chunk_model_102 AUC SCORE: 0.6861549563433423\n",
      "bow_chunk_model_103 AUC SCORE: 0.6861578606170118\n",
      "bow_chunk_model_104 AUC SCORE: 0.6861616498531571\n",
      "bow_chunk_model_105 AUC SCORE: 0.6861563795070312\n",
      "bow_chunk_model_106 AUC SCORE: 0.6861618965780554\n",
      "bow_chunk_model_107 AUC SCORE: 0.6861604559202875\n",
      "bow_chunk_model_108 AUC SCORE: 0.6861558115149528\n",
      "bow_chunk_model_109 AUC SCORE: 0.6861584719952188\n",
      "bow_chunk_model_110 AUC SCORE: 0.6861561126155765\n",
      "bow_chunk_model_111 AUC SCORE: 0.6861578949956313\n",
      "bow_chunk_model_112 AUC SCORE: 0.6861567062668315\n",
      "bow_chunk_model_113 AUC SCORE: 0.6861586329664999\n",
      "bow_chunk_model_114 AUC SCORE: 0.6861595853945175\n",
      "bow_chunk_model_115 AUC SCORE: 0.6861585421932722\n",
      "bow_chunk_model_116 AUC SCORE: 0.6861574464487883\n",
      "bow_chunk_model_117 AUC SCORE: 0.6861550066038394\n",
      "bow_chunk_model_118 AUC SCORE: 0.6861561100612299\n",
      "bow_chunk_model_119 AUC SCORE: 0.6861631436628841\n",
      "bow_chunk_model_120 AUC SCORE: 0.6861603023188142\n",
      "bow_chunk_model_121 AUC SCORE: 0.686155220858464\n",
      "bow_chunk_model_122 AUC SCORE: 0.6861489198941612\n",
      "bow_chunk_model_123 AUC SCORE: 0.6861562565168894\n",
      "bow_chunk_model_124 AUC SCORE: 0.6861569981595103\n",
      "bow_chunk_model_125 AUC SCORE: 0.686156800431167\n",
      "bow_chunk_model_126 AUC SCORE: 0.6861576129208871\n",
      "bow_chunk_model_127 AUC SCORE: 0.6861594270371328\n",
      "bow_chunk_model_128 AUC SCORE: 0.6861608215357545\n",
      "bow_chunk_model_129 AUC SCORE: 0.6861598294648513\n",
      "bow_chunk_model_130 AUC SCORE: 0.6861602751634719\n",
      "bow_chunk_model_131 AUC SCORE: 0.6861548358451883\n",
      "bow_chunk_model_132 AUC SCORE: 0.6861571998241079\n",
      "bow_chunk_model_133 AUC SCORE: 0.6861586222480239\n",
      "bow_chunk_model_134 AUC SCORE: 0.6861574705961665\n",
      "bow_chunk_model_135 AUC SCORE: 0.6861589139610851\n",
      "bow_chunk_model_136 AUC SCORE: 0.6861559438263295\n",
      "bow_chunk_model_137 AUC SCORE: 0.6861542760045554\n",
      "bow_chunk_model_138 AUC SCORE: 0.6861569582132284\n",
      "bow_chunk_model_139 AUC SCORE: 0.6861571474895359\n",
      "bow_chunk_model_140 AUC SCORE: 0.6861586287994679\n",
      "bow_chunk_model_141 AUC SCORE: 0.6861640490260916\n",
      "bow_chunk_model_142 AUC SCORE: 0.6861605545686105\n",
      "bow_chunk_model_143 AUC SCORE: 0.686163338016264\n",
      "bow_chunk_model_144 AUC SCORE: 0.6861569182519383\n",
      "bow_chunk_model_145 AUC SCORE: 0.6861560198859205\n",
      "bow_chunk_model_146 AUC SCORE: 0.6861562230097301\n",
      "bow_chunk_model_147 AUC SCORE: 0.686156864787857\n",
      "bow_chunk_model_148 AUC SCORE: 0.6861570159469808\n",
      "bow_chunk_model_149 AUC SCORE: 0.6861565828661349\n",
      "bow_chunk_model_150 AUC SCORE: 0.686159604826627\n",
      "bow_chunk_model_151 AUC SCORE: 0.6861553843469642\n",
      "bow_chunk_model_152 AUC SCORE: 0.6861579142074548\n",
      "bow_chunk_model_153 AUC SCORE: 0.6861544479145981\n",
      "bow_chunk_model_154 AUC SCORE: 0.6861549542842758\n",
      "bow_chunk_model_155 AUC SCORE: 0.6861579876192595\n",
      "bow_chunk_model_156 AUC SCORE: 0.6861589805779211\n",
      "bow_chunk_model_157 AUC SCORE: 0.6861526086664417\n",
      "bow_chunk_model_158 AUC SCORE: 0.6861557870830827\n",
      "bow_chunk_model_159 AUC SCORE: 0.6861597920666223\n",
      "bow_chunk_model_160 AUC SCORE: 0.6861555317844688\n",
      "bow_chunk_model_161 AUC SCORE: 0.6861583703602083\n",
      "bow_chunk_model_162 AUC SCORE: 0.6861505091833338\n",
      "bow_chunk_model_163 AUC SCORE: 0.686157706587395\n",
      "bow_chunk_model_164 AUC SCORE: 0.6861606227855443\n",
      "bow_chunk_model_165 AUC SCORE: 0.6861577526489065\n",
      "bow_chunk_model_166 AUC SCORE: 0.6861635634954474\n",
      "bow_chunk_model_167 AUC SCORE: 0.6861566770588756\n",
      "bow_chunk_model_168 AUC SCORE: 0.6861620545892766\n",
      "bow_chunk_model_169 AUC SCORE: 0.6861566828371406\n",
      "bow_chunk_model_170 AUC SCORE: 0.6861586792879968\n",
      "bow_chunk_model_171 AUC SCORE: 0.6861588500060757\n",
      "bow_chunk_model_172 AUC SCORE: 0.6861525429133196\n",
      "bow_chunk_model_173 AUC SCORE: 0.6861543786180221\n",
      "bow_chunk_model_174 AUC SCORE: 0.686156880651821\n",
      "bow_chunk_model_175 AUC SCORE: 0.6861608005643871\n",
      "bow_chunk_model_176 AUC SCORE: 0.6861586295808771\n",
      "bow_chunk_model_177 AUC SCORE: 0.6861601709150491\n",
      "bow_chunk_model_178 AUC SCORE: 0.6861594282474943\n",
      "bow_chunk_model_179 AUC SCORE: 0.6861566977836508\n",
      "bow_chunk_model_180 AUC SCORE: 0.6861561977199561\n",
      "bow_chunk_model_181 AUC SCORE: 0.68616489877141\n",
      "bow_chunk_model_182 AUC SCORE: 0.6861585978079234\n",
      "bow_chunk_model_183 AUC SCORE: 0.6861571879175414\n",
      "bow_chunk_model_184 AUC SCORE: 0.6861599644535472\n",
      "bow_chunk_model_185 AUC SCORE: 0.6861560140800593\n",
      "bow_chunk_model_186 AUC SCORE: 0.6861587831016579\n",
      "bow_chunk_model_187 AUC SCORE: 0.6861574152572922\n",
      "bow_chunk_model_188 AUC SCORE: 0.6861594854636959\n",
      "bow_chunk_model_189 AUC SCORE: 0.6861567145486079\n",
      "bow_chunk_model_190 AUC SCORE: 0.686158810080128\n",
      "bow_chunk_model_191 AUC SCORE: 0.6861586691175726\n",
      "bow_chunk_model_192 AUC SCORE: 0.686156991185408\n",
      "bow_chunk_model_193 AUC SCORE: 0.6861604618529948\n",
      "bow_chunk_model_194 AUC SCORE: 0.6861597467850679\n",
      "bow_chunk_model_195 AUC SCORE: 0.6861570417300978\n",
      "bow_chunk_model_196 AUC SCORE: 0.6861638924882224\n",
      "bow_chunk_model_197 AUC SCORE: 0.6861618162720325\n",
      "bow_chunk_model_198 AUC SCORE: 0.6861603074728577\n",
      "bow_chunk_model_199 AUC SCORE: 0.6861601833086652\n",
      "bow_chunk_model_200 AUC SCORE: 0.6861573133032305\n",
      "bow_chunk_model_201 AUC SCORE: 0.6861644662260283\n",
      "bow_chunk_model_202 AUC SCORE: 0.6861556315347046\n",
      "bow_chunk_model_203 AUC SCORE: 0.6861572561436738\n",
      "bow_chunk_model_204 AUC SCORE: 0.6861606255538829\n",
      "bow_chunk_model_205 AUC SCORE: 0.6861614468649081\n",
      "bow_chunk_model_206 AUC SCORE: 0.6861571753017028\n",
      "bow_chunk_model_207 AUC SCORE: 0.6861596928925184\n",
      "bow_chunk_model_208 AUC SCORE: 0.6861638031581293\n",
      "bow_chunk_model_209 AUC SCORE: 0.686157230167383\n",
      "bow_chunk_model_210 AUC SCORE: 0.6861598417437249\n",
      "bow_chunk_model_211 AUC SCORE: 0.6861570408450819\n",
      "bow_chunk_model_212 AUC SCORE: 0.6861566735478595\n",
      "bow_chunk_model_213 AUC SCORE: 0.686157239560755\n",
      "bow_chunk_model_214 AUC SCORE: 0.6861583111507837\n",
      "bow_chunk_model_215 AUC SCORE: 0.6861523356883218\n",
      "bow_chunk_model_216 AUC SCORE: 0.6861534352764291\n",
      "bow_chunk_model_217 AUC SCORE: 0.6861640612638132\n",
      "bow_chunk_model_218 AUC SCORE: 0.6861592187034442\n",
      "bow_chunk_model_219 AUC SCORE: 0.6861533826015034\n",
      "bow_chunk_model_220 AUC SCORE: 0.6861622211713088\n",
      "bow_chunk_model_221 AUC SCORE: 0.6861586792473288\n",
      "bow_chunk_model_222 AUC SCORE: 0.6861662421141888\n",
      "bow_chunk_model_223 AUC SCORE: 0.6861566561844997\n",
      "bow_chunk_model_224 AUC SCORE: 0.686151477459823\n",
      "bow_chunk_model_225 AUC SCORE: 0.6861629331237658\n",
      "bow_chunk_model_226 AUC SCORE: 0.6861514805883651\n",
      "bow_chunk_model_227 AUC SCORE: 0.6861600801418214\n",
      "bow_chunk_model_228 AUC SCORE: 0.6861572502879457\n",
      "bow_chunk_model_229 AUC SCORE: 0.6861604091974348\n",
      "bow_chunk_model_230 AUC SCORE: 0.686155859150418\n",
      "bow_chunk_model_231 AUC SCORE: 0.686159189082997\n",
      "bow_chunk_model_232 AUC SCORE: 0.6861601338416812\n",
      "bow_chunk_model_233 AUC SCORE: 0.6861569465729414\n",
      "bow_chunk_model_234 AUC SCORE: 0.6861587153359469\n",
      "bow_chunk_model_235 AUC SCORE: 0.6861520715598798\n",
      "bow_chunk_model_236 AUC SCORE: 0.6861564043480033\n",
      "bow_chunk_model_237 AUC SCORE: 0.6861570034807428\n",
      "bow_chunk_model_238 AUC SCORE: 0.6861530315749265\n",
      "bow_chunk_model_239 AUC SCORE: 0.6861624879359177\n",
      "bow_chunk_model_240 AUC SCORE: 0.6861555734872269\n",
      "bow_chunk_model_241 AUC SCORE: 0.6861555654562375\n",
      "bow_chunk_model_242 AUC SCORE: 0.6861650970247253\n",
      "bow_chunk_model_243 AUC SCORE: 0.6861582906467786\n",
      "bow_chunk_model_244 AUC SCORE: 0.686161881014261\n",
      "bow_chunk_model_245 AUC SCORE: 0.6861589481813894\n",
      "bow_chunk_model_246 AUC SCORE: 0.6861592189285715\n",
      "bow_chunk_model_247 AUC SCORE: 0.6861613806276415\n",
      "bow_chunk_model_248 AUC SCORE: 0.6861531338625638\n",
      "bow_chunk_model_249 AUC SCORE: 0.6861554336866182\n",
      "bow_chunk_model_250 AUC SCORE: 0.6861582940604817\n",
      "bow_chunk_model_251 AUC SCORE: 0.6861544065943141\n",
      "bow_chunk_model_252 AUC SCORE: 0.6861565725180296\n",
      "bow_chunk_model_253 AUC SCORE: 0.6861527397766558\n",
      "bow_chunk_model_254 AUC SCORE: 0.6861575030128472\n",
      "bow_chunk_model_255 AUC SCORE: 0.6861595671868099\n",
      "bow_chunk_model_256 AUC SCORE: 0.6861573600793391\n",
      "bow_chunk_model_257 AUC SCORE: 0.6861579243420525\n",
      "bow_chunk_model_258 AUC SCORE: 0.6861597694275395\n",
      "bow_chunk_model_259 AUC SCORE: 0.6861568374370794\n",
      "bow_chunk_model_260 AUC SCORE: 0.6861583567751126\n",
      "bow_chunk_model_261 AUC SCORE: 0.6861585632041768\n",
      "bow_chunk_model_262 AUC SCORE: 0.6861585853382969\n",
      "bow_chunk_model_263 AUC SCORE: 0.6861579448862417\n",
      "bow_chunk_model_264 AUC SCORE: 0.6861570363570619\n",
      "bow_chunk_model_265 AUC SCORE: 0.6861592324303943\n",
      "bow_chunk_model_266 AUC SCORE: 0.6861609176276315\n",
      "bow_chunk_model_267 AUC SCORE: 0.6861561141769426\n",
      "bow_chunk_model_268 AUC SCORE: 0.6861602131450407\n",
      "bow_chunk_model_269 AUC SCORE: 0.6861515516118843\n",
      "bow_chunk_model_270 AUC SCORE: 0.6861590467173907\n",
      "bow_chunk_model_271 AUC SCORE: 0.6861625918333357\n",
      "bow_chunk_model_272 AUC SCORE: 0.686153523698651\n",
      "bow_chunk_model_273 AUC SCORE: 0.686157778429119\n",
      "bow_chunk_model_274 AUC SCORE: 0.6861571032982747\n",
      "bow_chunk_model_275 AUC SCORE: 0.6861568716820752\n",
      "bow_chunk_model_276 AUC SCORE: 0.6861535797872801\n",
      "bow_chunk_model_277 AUC SCORE: 0.6861543573442269\n",
      "bow_chunk_model_278 AUC SCORE: 0.68615823753467\n",
      "bow_chunk_model_279 AUC SCORE: 0.6861596762093817\n",
      "bow_chunk_model_280 AUC SCORE: 0.6861621823332338\n",
      "bow_chunk_model_281 AUC SCORE: 0.6861576368638035\n",
      "bow_chunk_model_282 AUC SCORE: 0.6861584692510878\n",
      "bow_chunk_model_283 AUC SCORE: 0.6861655460745943\n",
      "bow_chunk_model_284 AUC SCORE: 0.6861606175577515\n",
      "bow_chunk_model_285 AUC SCORE: 0.6861530717109928\n",
      "bow_chunk_model_286 AUC SCORE: 0.6861592233013647\n",
      "bow_chunk_model_287 AUC SCORE: 0.6861627438532683\n",
      "bow_chunk_model_288 AUC SCORE: 0.6861539564769065\n",
      "bow_chunk_model_289 AUC SCORE: 0.686156687048714\n",
      "bow_chunk_model_290 AUC SCORE: 0.686156017971129\n",
      "bow_chunk_model_291 AUC SCORE: 0.6861538802609365\n",
      "bow_chunk_model_292 AUC SCORE: 0.686156762806683\n",
      "bow_chunk_model_293 AUC SCORE: 0.6861584423103807\n",
      "bow_chunk_model_294 AUC SCORE: 0.6861600729677675\n",
      "bow_chunk_model_295 AUC SCORE: 0.6861593325781127\n",
      "bow_chunk_model_296 AUC SCORE: 0.6861666626581115\n",
      "bow_chunk_model_297 AUC SCORE: 0.6861627229372559\n",
      "bow_chunk_model_298 AUC SCORE: 0.6861611724062743\n",
      "bow_chunk_model_299 AUC SCORE: 0.6861512020890607\n",
      "bow_chunk_model_300 AUC SCORE: 0.6861557837628195\n",
      "bow_chunk_model_301 AUC SCORE: 0.6861605111979745\n",
      "bow_chunk_model_302 AUC SCORE: 0.6861518742540353\n",
      "bow_chunk_model_303 AUC SCORE: 0.6861615868427137\n",
      "bow_chunk_model_304 AUC SCORE: 0.6861559549785987\n",
      "bow_chunk_model_305 AUC SCORE: 0.686163716644405\n",
      "bow_chunk_model_306 AUC SCORE: 0.6861570078825849\n",
      "bow_chunk_model_307 AUC SCORE: 0.6861604075658678\n",
      "bow_chunk_model_308 AUC SCORE: 0.6861596877344426\n",
      "bow_chunk_model_309 AUC SCORE: 0.686160407975454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Emma\\anaconda3\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 39253)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Emma\\anaconda3\\Lib\\socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"C:\\Users\\Emma\\anaconda3\\Lib\\socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"C:\\Users\\Emma\\anaconda3\\Lib\\socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"C:\\Users\\Emma\\anaconda3\\Lib\\socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\pyspark\\accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\pyspark\\accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\pyspark\\accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\pyspark\\serializers.py\", line 594, in read_int\n",
      "    length = stream.read(4)\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Emma\\anaconda3\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "----------------------------------------\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Emma\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1340, in time\n",
      "    exec(code, glob, local_ns)\n",
      "  File \"<timed exec>\", line 40, in <module>\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\pyspark\\ml\\evaluation.py\", line 111, in evaluate\n",
      "    return self._evaluate(dataset)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\pyspark\\ml\\evaluation.py\", line 148, in _evaluate\n",
      "    return self._java_obj.evaluate(dataset._jdf)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py\", line 1322, in __call__\n",
      "    return_value = get_return_value(\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\pyspark\\errors\\exceptions\\captured.py\", line 179, in deco\n",
      "    return f(*a, **kw)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <exception str() failed>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Emma\\anaconda3\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[WinError 10061] No connection could be made because the target machine actively refused it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:1340\u001b[0m, in \u001b[0;36mExecutionMagics.time\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1340\u001b[0m     exec(code, glob, local_ns)\n\u001b[0;32m   1341\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m<timed exec>:40\u001b[0m\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.1-bin-hadoop3\\python\\pyspark\\ml\\evaluation.py:111\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(dataset)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.1-bin-hadoop3\\python\\pyspark\\ml\\evaluation.py:148\u001b[0m, in \u001b[0;36mJavaEvaluator._evaluate\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj\u001b[38;5;241m.\u001b[39mevaluate(dataset\u001b[38;5;241m.\u001b[39m_jdf)\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.1-bin-hadoop3\\python\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_cell_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mcur_run = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mfile_end = False\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mwhile not file_end:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    # Read json with file open\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    f = open(file_path, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    f_content = \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    for i in range(chunk_size_line):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        line = f.readline()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        if line:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m            f_content += line\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        else: # last training when file reach end\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m            file_end = True\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m            break \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    # write to a tmp json file\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    with open(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtmp.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) as outfile:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        outfile.write(f_content)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    # create df\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    df = spark.read.schema(schema).json(r\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mEmma\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mschool\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mBig_Data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mbig-data-final-project\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtmp.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    # pre-process\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    df_labeled_cleaned = preProc(df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    # training\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    if cur_run<0: # skip this for now since model load is not working\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        model_path = r\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mEmma\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mschool\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mBig_Data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mbig-data-final-project\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mbow_chunk_model_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.format(cur_run)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        prev_model = PipelineModel.load(model_path)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        stages_steps = prev_model.stages\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        model = Pipeline(stages = stages_steps).fit(df_labeled_cleaned) \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    else: # the first time training\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        model = basic_pipline.fit(df_labeled_cleaned)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    cur_run += 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    model_name = \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbow_chunk_model_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.format(cur_run)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    #model.save(model_name) # skip since model load is not working\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    # get score from testing data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    predictions = model.transform(df_test)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    score = evaluator.evaluate(predictions)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    print(\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m AUC SCORE: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.format(model_name, score))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    # free memory\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    spark.catalog.clearCache()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    del f_content\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    del df\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m    del df_labeled_cleaned\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[1;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:1347\u001b[0m, in \u001b[0;36mExecutionMagics.time\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(code_2, glob, local_ns)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m-> 1347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mshowtraceback()\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m end \u001b[38;5;241m=\u001b[39m clock2()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2155\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2152\u001b[0m         traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[0;32m   2153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_showtraceback(etype, value, stb)\n\u001b[0;32m   2156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_pdb:\n\u001b[0;32m   2157\u001b[0m     \u001b[38;5;66;03m# drop into debugger\u001b[39;00m\n\u001b[0;32m   2158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebugger(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py:559\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[1;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[0;32m    553\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    554\u001b[0m sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    556\u001b[0m exc_content \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraceback\u001b[39m\u001b[38;5;124m\"\u001b[39m: stb,\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mename\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(etype\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m),\n\u001b[1;32m--> 559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(evalue),\n\u001b[0;32m    560\u001b[0m }\n\u001b[0;32m    562\u001b[0m dh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayhook\n\u001b[0;32m    563\u001b[0m \u001b[38;5;66;03m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# to pick up\u001b[39;00m\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\protocol.py:471\u001b[0m, in \u001b[0;36mPy4JJavaError.__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__str__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    470\u001b[0m     gateway_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_exception\u001b[38;5;241m.\u001b[39m_gateway_client\n\u001b[1;32m--> 471\u001b[0m     answer \u001b[38;5;241m=\u001b[39m gateway_client\u001b[38;5;241m.\u001b[39msend_command(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception_cmd)\n\u001b[0;32m    472\u001b[0m     return_value \u001b[38;5;241m=\u001b[39m get_return_value(answer, gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;66;03m# Note: technically this should return a bytestring 'str' rather than\u001b[39;00m\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;66;03m# unicodes in Python 2; however, it can return unicodes for now.\u001b[39;00m\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# See https://github.com/bartdag/py4j/issues/306 for more details.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_new_connection()\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 291\u001b[0m     connection\u001b[38;5;241m.\u001b[39mconnect_to_java_server()\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[1;32mC:\\spark\\spark-3.5.1-bin-hadoop3\\python\\lib\\py4j-0.10.9.7-src.zip\\py4j\\clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[1;32m--> 438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mconnect((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_port))\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cur_run = 0\n",
    "file_end = False\n",
    "while not file_end:\n",
    "    \n",
    "    # Read json with file open\n",
    "    f = open(file_path, \"r\")\n",
    "    f_content = ''\n",
    "    for i in range(chunk_size_line):\n",
    "        line = f.readline()\n",
    "        if line:\n",
    "            f_content += line\n",
    "        else: # last training when file reach end\n",
    "            file_end = True\n",
    "            break \n",
    "    # write to a tmp json file\n",
    "    with open(\"tmp.json\", \"w\") as outfile:\n",
    "        outfile.write(f_content)\n",
    "    \n",
    "    # create df\n",
    "    df = spark.read.schema(schema).json(r\"C:\\Users\\Emma\\Downloads\\school\\Big_Data\\project\\big-data-final-project\\tmp.json\")\n",
    "    \n",
    "    # pre-process\n",
    "    df_labeled_cleaned = preProc(df)\n",
    "    \n",
    "    # training\n",
    "    if cur_run<0: # skip this for now since model load is not working\n",
    "        model_path = r\"C:\\Users\\Emma\\Downloads\\school\\Big_Data\\project\\big-data-final-project\\bow_chunk_model_{}\".format(cur_run)\n",
    "        prev_model = PipelineModel.load(model_path)\n",
    "        stages_steps = prev_model.stages\n",
    "        model = Pipeline(stages = stages_steps).fit(df_labeled_cleaned) \n",
    "    else: # the first time training\n",
    "        model = basic_pipline.fit(df_labeled_cleaned)\n",
    "        \n",
    "    cur_run += 1\n",
    "    model_name = \"bow_chunk_model_{}\".format(cur_run)\n",
    "    #model.save(model_name) # skip since model load is not working\n",
    "    \n",
    "    # get score from testing data\n",
    "    predictions = model.transform(df_test)\n",
    "    score = evaluator.evaluate(predictions)\n",
    "    print(\"{} AUC SCORE: {}\".format(model_name, score))\n",
    "\n",
    "    # free memory\n",
    "    spark.catalog.clearCache()\n",
    "    del f_content\n",
    "    del df\n",
    "    del df_labeled_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73c071a1-4c3f-420e-8169-5d501c64b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pipelineModel load testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee70a96-4ae7-429f-b41e-cd1655225d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.ml.pipeline import PipelineModel \n",
    "data_path = \"tmp_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cddc333-3b6a-47c1-9761-392111f24186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc0fb6cc-e9eb-40ec-97dd-4cbde31e269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PipelineModel.load(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d3f87b-0cac-40a6-afe3-6a5be8fe4e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.pipeline.PipelineModel"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27274c-c605-403e-a94b-98e0469ec87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
